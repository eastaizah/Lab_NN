# Gu√≠a de Laboratorio: Autoencoders para Sistemas de Comunicaci√≥n

## üìã Informaci√≥n del Laboratorio

**T√≠tulo:** Fundamentos de Deep Learning para Comunicaciones - Autoencoder End-to-End  
**C√≥digo:** Gu√≠a 03  
**Duraci√≥n:** 3-4 horas  
**Nivel:** B√°sico-Intermedio  

## üéØ Objetivos Espec√≠ficos

Al completar este laboratorio, ser√°s capaz de:

1. Comprender el concepto de sistema de comunicaci√≥n como autoencoder end-to-end
2. Identificar la analog√≠a entre capas de una red neuronal y componentes de comunicaci√≥n
3. Implementar y entrenar un autoencoder para comunicaciones en PyTorch
4. Dise√±ar arquitecturas neuronales para encoder y decoder adaptativos
5. Evaluar rendimiento mediante curvas BER vs SNR en canal AWGN
6. Visualizar y analizar constelaciones aprendidas autom√°ticamente
7. Comparar el rendimiento con modulaciones cl√°sicas (QAM, PSK)
8. Comprender las ventajas del aprendizaje end-to-end sobre dise√±o tradicional

## üìö Prerrequisitos

### Conocimientos
- Python intermedio (POO, NumPy)
- Fundamentos de redes neuronales (capas densas, backpropagation)
- Conceptos b√°sicos de sistemas de comunicaciones digitales
- Modulaci√≥n digital y SNR
- M√©tricas de rendimiento (BER, SER)

### Software
- Python 3.8+
- PyTorch 2.0+
- NumPy, Matplotlib
- Jupyter Notebook

### Material de Lectura
Antes de comenzar, lee:
- `teoria.md` - Marco te√≥rico completo sobre autoencoders para comunicaciones
- `README.md` - Estructura del laboratorio y recursos disponibles

## üìñ Introducci√≥n

Los **autoencoders end-to-end para comunicaciones** representan un cambio de paradigma en el dise√±o de sistemas de comunicaciones digitales:

- **Dise√±o Tradicional:** Componentes independientes optimizados separadamente (codificador, modulador, demodulador, decodificador)
- **Deep Learning:** Optimizaci√≥n conjunta de todo el sistema mediante backpropagation

### Contexto del Problema

En sistemas de comunicaci√≥n tradicionales, cada componente se dise√±a seg√∫n principios te√≥ricos de teor√≠a de la informaci√≥n y comunicaciones:
- El modulador mapea bits a s√≠mbolos seg√∫n constelaciones predefinidas (QAM, PSK, etc.)
- El demodulador toma decisiones basadas en distancias euclidianas
- Los l√≠mites te√≥ricos (Shannon, AWGN) gu√≠an el dise√±o

Sin embargo, este enfoque modular puede ser **sub√≥ptimo** cuando:
1. Los componentes no est√°n perfectamente sincronizados
2. Existen imperfecciones de hardware no modeladas
3. El canal tiene caracter√≠sticas complejas dif√≠ciles de modelar
4. Se requiere adaptaci√≥n din√°mica a condiciones cambiantes

### Enfoque con Autoencoders

El paradigma de **autoencoder** trata el sistema de comunicaci√≥n completo como una red neuronal:

```
                    AUTOENCODER PARA COMUNICACIONES
                    
Mensaje (k bits)                                      Mensaje estimado
    ‚Üì                                                      ‚Üë
[ENCODER = Transmisor]                         [DECODER = Receptor]
    ‚Üì                                                      ‚Üë
Se√±al (n dimensiones)      ‚Üí  CANAL AWGN  ‚Üí      Se√±al + Ruido
```

**Ventajas clave:**
- **Aprendizaje autom√°tico de modulaci√≥n:** No necesitas dise√±ar constelaciones manualmente
- **Optimizaci√≥n global:** El sistema completo se optimiza para minimizar errores
- **Adaptabilidad:** El modelo puede entrenarse para diferentes condiciones de canal
- **Descubrimiento de soluciones:** Puede encontrar esquemas mejores que los cl√°sicos

### Conceptos Fundamentales

**1. Restricci√≥n de Potencia:**
En sistemas reales, la potencia de transmisi√≥n est√° limitada. El encoder debe normalizar:
$$P_{avg} = \mathbb{E}[\|\mathbf{x}\|^2] = 1$$

**2. Canal Diferenciable:**
El canal AWGN es diferenciable, permitiendo backpropagation:
$$\mathbf{y} = \mathbf{x} + \mathbf{n}, \quad \mathbf{n} \sim \mathcal{N}(0, \sigma^2 I)$$

**3. Funci√≥n de P√©rdida:**
Cross-entropy entre mensaje original y estimado (clasificaci√≥n):
$$\mathcal{L} = -\frac{1}{N}\sum_{i=1}^{N} \log P(\hat{m}_i = m_i)$$

### Aplicaciones Pr√°cticas

- **IoT y 5G:** Dise√±o de esquemas de modulaci√≥n adaptativos
- **Comunicaciones √ìpticas:** Optimizaci√≥n para distorsiones no lineales
- **Sat√©lites:** Adaptaci√≥n a canales variables
- **Sistemas Embebidos:** Modulaciones eficientes en recursos

## üî¨ Parte 1: Preparaci√≥n y Conceptos Fundamentales (30 min)

### 1.1 Introducci√≥n a Autoencoders para Comunicaciones

Un sistema de comunicaci√≥n tradicional consta de componentes dise√±ados independientemente (codificador, modulador, canal, demodulador, decodificador). El paradigma de **autoencoder end-to-end** propone entrenar una red neuronal completa que optimiza todo el sistema de forma conjunta.

```
Sistema Tradicional:
Mensaje ‚Üí [Codificador] ‚Üí [Modulador] ‚Üí [Canal AWGN] ‚Üí [Demodulador] ‚Üí [Decodificador] ‚Üí Mensaje estimado

Sistema Autoencoder:
Mensaje (M opciones)
    ‚Üì
[ENCODER - Red Neuronal Dense + ReLU]
    ‚Üì
S√≠mbolos (n dimensiones, potencia normalizada)
    ‚Üì
[CANAL AWGN - Ruido Gaussiano]
    ‚Üì
S√≠mbolos recibidos con ruido
    ‚Üì
[DECODER - Red Neuronal Dense + Softmax]
    ‚Üì
Mensaje estimado (probabilidades sobre M opciones)
```

**Pregunta de Reflexi√≥n 1:** ¬øPor qu√© es ventajoso optimizar todo el sistema de comunicaci√≥n de forma conjunta en lugar de dise√±ar cada componente independientemente?

### 1.2 Preparaci√≥n del Entorno

```python
# Importar bibliotecas necesarias
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from tqdm import tqdm

# Importar m√≥dulos del laboratorio
from autoencoder import CommunicationNet
from utils import (
    train_communication_system,
    evaluate_ber,
    plot_constellation,
    plot_ber_curve,
    compare_with_standard_modulation,
    add_awgn_noise
)

# Configuraci√≥n de dispositivo
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üñ•Ô∏è  Usando dispositivo: {device}")

# Semilla para reproducibilidad
torch.manual_seed(42)
np.random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
```

### 1.3 Comprensi√≥n de Par√°metros Clave

Los par√°metros fundamentales del sistema son:

- **M (num_messages):** N√∫mero de mensajes distintos a transmitir. Equivale a $2^k$ donde $k$ es el n√∫mero de bits por mensaje.
- **n (signal_dims):** Dimensi√≥n del espacio de se√±al (n√∫mero de componentes del s√≠mbolo transmitido). Para n=2, equivale a I/Q (In-phase/Quadrature).
- **SNR (Signal-to-Noise Ratio):** Relaci√≥n se√±al a ruido en dB. Define la cantidad de ruido en el canal AWGN.

**Restricci√≥n de potencia:** La potencia promedio de transmisi√≥n debe normalizarse a 1:
$$P_{avg} = \mathbb{E}[\|\mathbf{x}\|^2] = 1$$

**Actividad 1:** Calcula cu√°ntos bits por mensaje se transmiten para M=16, M=4 y M=64. ¬øC√≥mo afecta M a la complejidad del problema?

### Actividades

**Actividad 1.1:** Verifica que el entorno est√© configurado correctamente y que todos los m√≥dulos se importen sin errores.

**Actividad 1.2:** Calcula manualmente:
- Para M=4: ¬øcu√°ntos bits por s√≠mbolo?
- Para M=16: ¬øcu√°ntos bits por s√≠mbolo?
- Para M=64: ¬øcu√°ntos bits por s√≠mbolo?

**Actividad 1.3:** Ejecuta el test r√°pido y verifica que la normalizaci√≥n de potencia est√© funcionando.

### Preguntas de Reflexi√≥n

**Pregunta 1.1 (Concebir):** ¬øPor qu√© es ventajoso optimizar todo el sistema de comunicaci√≥n de forma conjunta en lugar de dise√±ar cada componente independientemente? Piensa en t√©rminos de optimizaci√≥n global vs local.

**Pregunta 1.2 (Dise√±ar):** ¬øPor qu√© es necesaria la restricci√≥n de potencia en el encoder? ¬øQu√© pasar√≠a si permitimos potencia infinita?

**Pregunta 1.3 (Operar):** En aplicaciones reales, ¬øqu√© otros factores adem√°s de la potencia deber√≠an restringirse (latencia, ancho de banda, complejidad)?

## üî¨ Parte 2: Implementaci√≥n del Autoencoder B√°sico (60 min)

### 2.1 Arquitectura del Autoencoder

El autoencoder consta de dos componentes principales:

```python
# Crear el modelo de comunicaci√≥n
# M=16 mensajes, n=2 dimensiones (equivalente a I/Q)
model = CommunicationNet(
    num_messages=16,      # M = 16 (4 bits por mensaje)
    signal_dims=2,        # n = 2 (se√±al compleja I/Q)
    intermediate_size=64  # Tama√±o de capa oculta
).to(device)

# Ver arquitectura
print("\nüìê Arquitectura del Modelo:")
print(model)

# Contar par√°metros
total_params = sum(p.numel() for p in model.parameters())
print(f"\nüìä Total de par√°metros: {total_params:,}")
```

**Pregunta de Reflexi√≥n 2:** ¬øPor qu√© el encoder necesita una capa de normalizaci√≥n de potencia? ¬øQu√© ocurrir√≠a sin ella?

### 2.2 Visualizaci√≥n de Constelaci√≥n Inicial (sin entrenamiento)

```python
# Visualizar constelaci√≥n antes del entrenamiento
print("\nüåå Constelaci√≥n ANTES del entrenamiento:")

model.eval()
with torch.no_grad():
    # Generar todos los mensajes posibles
    messages = torch.arange(0, 16).to(device)
    
    # Codificar mensajes a s√≠mbolos
    symbols = model.encoder(messages)
    
    # Mover a CPU y convertir a NumPy
    symbols_np = symbols.cpu().numpy()
    
    # Graficar constelaci√≥n
    plt.figure(figsize=(8, 8))
    plt.scatter(symbols_np[:, 0], symbols_np[:, 1], s=100, c=range(16), cmap='tab20')
    plt.xlabel('Dimensi√≥n I (In-phase)', fontsize=12)
    plt.ylabel('Dimensi√≥n Q (Quadrature)', fontsize=12)
    plt.title('Constelaci√≥n Inicial (sin entrenar)', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    # A√±adir c√≠rculo de potencia unitaria
    circle = plt.Circle((0, 0), 1, color='r', fill=False, linestyle='--', 
                        linewidth=2, label='Potencia = 1')
    plt.gca().add_patch(circle)
    plt.legend()
    
    # Anotar cada punto con su mensaje
    for i, (x, y) in enumerate(symbols_np):
        plt.annotate(f'{i}', (x, y), fontsize=9, ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()

print(f"‚úì Potencia promedio: {np.mean(np.sum(symbols_np**2, axis=1)):.4f}")
```

**Actividad 2:** Observa la constelaci√≥n inicial. ¬øLos s√≠mbolos est√°n distribuidos uniformemente? ¬øCu√°l es la potencia promedio?

### 2.3 Entrenamiento del Autoencoder

```python
# Configurar hiperpar√°metros de entrenamiento
training_config = {
    'num_epochs': 100,
    'batch_size': 256,
    'learning_rate': 0.001,
    'snr_db_train': 10.0  # SNR de entrenamiento
}

print("\nüèãÔ∏è  Configuraci√≥n de Entrenamiento:")
for key, value in training_config.items():
    print(f"  {key}: {value}")

# Entrenar el modelo
print("\nüìà Iniciando entrenamiento...\n")

history = train_communication_system(
    model=model,
    num_epochs=training_config['num_epochs'],
    batch_size=training_config['batch_size'],
    learning_rate=training_config['learning_rate'],
    snr_db=training_config['snr_db_train'],
    device=device,
    verbose=True
)

print("\n‚úÖ Entrenamiento completado!")
```

**Pregunta de Reflexi√≥n 3:** ¬øPor qu√© se usa cross-entropy loss para entrenar el sistema? ¬øQu√© est√° optimizando realmente esta funci√≥n de p√©rdida?

### 2.4 Curvas de Entrenamiento

```python
# Graficar evoluci√≥n del loss y accuracy durante entrenamiento
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history['loss'], linewidth=2, color='#e74c3c')
axes[0].set_xlabel('√âpoca', fontsize=12)
axes[0].set_ylabel('Loss (Cross-Entropy)', fontsize=12)
axes[0].set_title('Evoluci√≥n del Loss durante Entrenamiento', fontsize=13, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Accuracy
axes[1].plot(history['accuracy'], linewidth=2, color='#27ae60')
axes[1].set_xlabel('√âpoca', fontsize=12)
axes[1].set_ylabel('Accuracy (%)', fontsize=12)
axes[1].set_title('Evoluci√≥n de la Accuracy durante Entrenamiento', fontsize=13, fontweight='bold')
axes[1].grid(True, alpha=0.3)
axes[1].set_ylim([0, 105])

plt.tight_layout()
plt.show()

print(f"\nüìä Resultados Finales de Entrenamiento:")
print(f"  Loss final: {history['loss'][-1]:.4f}")
print(f"  Accuracy final: {history['accuracy'][-1]:.2f}%")
```

**Actividad 3:** Experimenta con diferentes learning rates (0.0001, 0.001, 0.01). ¬øC√≥mo afecta la velocidad de convergencia?

### Actividades

**Actividad 2.1:** Ejecuta el c√≥digo de arquitectura y cuenta los par√°metros del encoder y decoder por separado.

**Actividad 2.2:** Visualiza la constelaci√≥n inicial y observa c√≥mo los s√≠mbolos est√°n distribuidos antes del entrenamiento.

**Actividad 2.3:** Entrena el modelo y analiza las curvas de loss y accuracy. ¬øHay se√±ales de overfitting o underfitting?

**Actividad 2.4:** Experimenta con diferentes learning rates y compara las curvas de entrenamiento.

### Preguntas de Reflexi√≥n

**Pregunta 2.1 (Concebir):** ¬øPor qu√© el encoder necesita una capa de normalizaci√≥n de potencia? ¬øQu√© ocurrir√≠a sin ella?

**Pregunta 2.2 (Dise√±ar):** ¬øPor qu√© se usa cross-entropy loss para entrenar el sistema? ¬øQu√© est√° optimizando realmente esta funci√≥n de p√©rdida?

**Pregunta 2.3 (Implementar):** ¬øCu√°l es el papel de la funci√≥n de activaci√≥n ReLU en el encoder? ¬øQu√© pasar√≠a si usamos otras activaciones como Sigmoid o Tanh?

**Pregunta 2.4 (Operar):** Analiza las curvas de entrenamiento. ¬øEn qu√© √©poca el modelo converge? ¬øSer√≠a beneficioso entrenar m√°s √©pocas?

## üî¨ Parte 3: An√°lisis de la Constelaci√≥n Aprendida (30 min)

### 3.1 Visualizaci√≥n de Constelaci√≥n Entrenada

```python
# Visualizar constelaci√≥n DESPU√âS del entrenamiento
print("\nüåå Constelaci√≥n DESPU√âS del entrenamiento:")

model.eval()
with torch.no_grad():
    messages = torch.arange(0, 16).to(device)
    symbols = model.encoder(messages)
    symbols_np = symbols.cpu().numpy()
    
    # Graficar constelaci√≥n aprendida
    plt.figure(figsize=(10, 10))
    plt.scatter(symbols_np[:, 0], symbols_np[:, 1], s=150, c=range(16), 
                cmap='tab20', edgecolors='black', linewidth=2)
    plt.xlabel('Dimensi√≥n I (In-phase)', fontsize=13)
    plt.ylabel('Dimensi√≥n Q (Quadrature)', fontsize=13)
    plt.title(f'Constelaci√≥n Aprendida (SNR entrenamiento = {training_config["snr_db_train"]} dB)', 
              fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    # C√≠rculo de potencia
    circle = plt.Circle((0, 0), 1, color='r', fill=False, linestyle='--', 
                        linewidth=2, label='Potencia = 1')
    plt.gca().add_patch(circle)
    plt.legend(fontsize=11)
    
    # Anotar puntos
    for i, (x, y) in enumerate(symbols_np):
        plt.annotate(f'{i}', (x, y), fontsize=10, ha='center', va='bottom', 
                     fontweight='bold')
    
    plt.tight_layout()
    plt.show()

# Calcular distancias m√≠nimas entre s√≠mbolos
distances = []
for i in range(len(symbols_np)):
    for j in range(i+1, len(symbols_np)):
        dist = np.linalg.norm(symbols_np[i] - symbols_np[j])
        distances.append(dist)

print(f"\nüìè An√°lisis de la Constelaci√≥n:")
print(f"  Potencia promedio: {np.mean(np.sum(symbols_np**2, axis=1)):.4f}")
print(f"  Distancia m√≠nima entre s√≠mbolos: {np.min(distances):.4f}")
print(f"  Distancia m√°xima entre s√≠mbolos: {np.max(distances):.4f}")
print(f"  Distancia promedio: {np.mean(distances):.4f}")
```

**Pregunta de Reflexi√≥n 4:** ¬øLa constelaci√≥n aprendida se asemeja a alguna modulaci√≥n cl√°sica (QAM, PSK)? ¬øPor qu√© el autoencoder eligi√≥ esta configuraci√≥n?

### 3.2 Comparaci√≥n con 16-QAM

```python
# Comparar con 16-QAM est√°ndar
print("\nüìä Comparaci√≥n con 16-QAM:")

# Generar constelaci√≥n 16-QAM est√°ndar
from utils import generate_qam_constellation

qam16_symbols = generate_qam_constellation(M=16, normalize=True)

# Graficar comparaci√≥n lado a lado
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# Autoencoder aprendido
axes[0].scatter(symbols_np[:, 0], symbols_np[:, 1], s=150, c=range(16), 
                cmap='tab20', edgecolors='black', linewidth=2)
axes[0].set_xlabel('I', fontsize=12)
axes[0].set_ylabel('Q', fontsize=12)
axes[0].set_title('Autoencoder Aprendido', fontsize=13, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].axis('equal')
circle1 = plt.Circle((0, 0), 1, color='r', fill=False, linestyle='--', linewidth=2)
axes[0].add_patch(circle1)

# 16-QAM est√°ndar
axes[1].scatter(qam16_symbols[:, 0], qam16_symbols[:, 1], s=150, c=range(16), 
                cmap='tab20', edgecolors='black', linewidth=2, marker='s')
axes[1].set_xlabel('I', fontsize=12)
axes[1].set_ylabel('Q', fontsize=12)
axes[1].set_title('16-QAM Est√°ndar', fontsize=13, fontweight='bold')
axes[1].grid(True, alpha=0.3)
axes[1].axis('equal')
circle2 = plt.Circle((0, 0), 1, color='r', fill=False, linestyle='--', linewidth=2)
axes[1].add_patch(circle2)

plt.tight_layout()
plt.show()
```

**Actividad 4:** Calcula la distancia m√≠nima para 16-QAM y comp√°rala con la del autoencoder. ¬øCu√°l tiene mejor separaci√≥n?

### Actividades

**Actividad 3.1:** Visualiza la constelaci√≥n aprendida y comp√°rala con la inicial (Parte 2). ¬øQu√© cambi√≥?

**Actividad 3.2:** Calcula la distancia m√≠nima entre s√≠mbolos para la constelaci√≥n aprendida y para 16-QAM. Compara los valores.

**Actividad 3.3:** Observa si la constelaci√≥n tiene alguna simetr√≠a o patr√≥n espec√≠fico.

### Preguntas de Reflexi√≥n

**Pregunta 3.1 (Concebir):** ¬øLa constelaci√≥n aprendida se asemeja a alguna modulaci√≥n cl√°sica (QAM, PSK)? ¬øPor qu√© el autoencoder eligi√≥ esta configuraci√≥n?

**Pregunta 3.2 (Dise√±ar):** ¬øC√≥mo podr√≠as modificar el entrenamiento para forzar al autoencoder a aprender una constelaci√≥n espec√≠fica (por ejemplo, parecida a QAM)?

**Pregunta 3.3 (Operar):** Si la distancia m√≠nima del autoencoder es mayor que 16-QAM, ¬øsignifica que siempre tendr√° mejor rendimiento? ¬øPor qu√© s√≠ o por qu√© no?

## üî¨ Parte 4: Evaluaci√≥n de Rendimiento BER vs SNR (60 min)

### 4.1 Evaluaci√≥n en Canal AWGN

```python
# Evaluar BER para diferentes valores de SNR
print("\nüì° Evaluando BER vs SNR en Canal AWGN...\n")

snr_range_db = np.arange(-4, 21, 2)  # De -4 dB a 20 dB
ber_autoencoder = []
num_test_blocks = 10000  # Bloques para evaluaci√≥n

for snr_db in tqdm(snr_range_db, desc="Evaluando SNR"):
    ber = evaluate_ber(
        model=model,
        snr_db=snr_db,
        num_blocks=num_test_blocks,
        device=device
    )
    ber_autoencoder.append(ber)
    print(f"  SNR = {snr_db:3d} dB ‚Üí BER = {ber:.6f}")

print("\n‚úÖ Evaluaci√≥n completada!")
```

### 4.2 Curvas BER vs SNR

```python
# Graficar curva BER vs SNR
plt.figure(figsize=(12, 7))
plt.semilogy(snr_range_db, ber_autoencoder, 'o-', linewidth=2.5, markersize=8,
             color='#3498db', label='Autoencoder (M=16, n=2)', markeredgecolor='black')

plt.xlabel('SNR (dB)', fontsize=13)
plt.ylabel('Bit Error Rate (BER)', fontsize=13)
plt.title('Rendimiento del Autoencoder en Canal AWGN', fontsize=14, fontweight='bold')
plt.grid(True, which='both', alpha=0.4)
plt.legend(fontsize=11, loc='lower left')
plt.ylim([1e-5, 1])
plt.tight_layout()
plt.show()

# Mostrar tabla de resultados
print("\nüìã Tabla de Resultados BER:")
print("=" * 40)
print(f"{'SNR (dB)':<12} {'BER':<15} {'SER (aprox.)':<15}")
print("=" * 40)
for snr, ber in zip(snr_range_db, ber_autoencoder):
    # Aproximaci√≥n SER para Gray coding: SER ‚âà 2 √ó BER (v√°lida para BER bajo)
    ser = 2 * ber  
    print(f"{snr:<12} {ber:<15.6f} {ser:<15.6f}")
print("=" * 40)
```

**Pregunta de Reflexi√≥n 5:** ¬øA partir de qu√© SNR el BER se vuelve pr√°cticamente cero? ¬øC√≥mo se relaciona esto con el SNR de entrenamiento?

### 4.3 Comparaci√≥n con Modulaciones Cl√°sicas

```python
# Comparar con QAM y PSK est√°ndar
print("\nüìä Comparando con modulaciones est√°ndar...\n")

ber_comparison = compare_with_standard_modulation(
    model=model,
    snr_range_db=snr_range_db,
    num_blocks=num_test_blocks,
    device=device
)

# Graficar comparaci√≥n completa
plt.figure(figsize=(12, 8))

plt.semilogy(snr_range_db, ber_autoencoder, 'o-', linewidth=2.5, markersize=9,
             label='Autoencoder (aprendido)', color='#e74c3c', markeredgecolor='black')
plt.semilogy(snr_range_db, ber_comparison['16-QAM'], 's-', linewidth=2.5, markersize=8,
             label='16-QAM (est√°ndar)', color='#3498db', markeredgecolor='black')
plt.semilogy(snr_range_db, ber_comparison['16-PSK'], '^-', linewidth=2.5, markersize=8,
             label='16-PSK (est√°ndar)', color='#2ecc71', markeredgecolor='black')

plt.xlabel('SNR (dB)', fontsize=13)
plt.ylabel('Bit Error Rate (BER)', fontsize=13)
plt.title('Comparaci√≥n: Autoencoder vs Modulaciones Cl√°sicas (M=16, Canal AWGN)', 
          fontsize=14, fontweight='bold')
plt.grid(True, which='both', alpha=0.4)
plt.legend(fontsize=11, loc='lower left')
plt.ylim([1e-5, 1])
plt.tight_layout()
plt.show()
```

**Actividad 5:** Identifica en qu√© rango de SNR el autoencoder supera o iguala a las modulaciones cl√°sicas. ¬øPor qu√©?

### Actividades

**Actividad 4.1:** Eval√∫a el BER del autoencoder en el rango completo de SNR y genera la tabla de resultados.

**Actividad 4.2:** Grafica la curva BER vs SNR en escala logar√≠tmica e identifica el SNR donde BER < 10^-3.

**Actividad 4.3:** Compara el autoencoder con 16-QAM y 16-PSK. ¬øEn qu√© rangos de SNR cada uno es superior?

**Actividad 4.4:** Calcula la ganancia de codificaci√≥n del autoencoder respecto a 16-QAM a BER = 10^-3.

### Preguntas de Reflexi√≥n

**Pregunta 4.1 (Concebir):** ¬øA partir de qu√© SNR el BER se vuelve pr√°cticamente cero? ¬øC√≥mo se relaciona esto con el SNR de entrenamiento (10 dB)?

**Pregunta 4.2 (Dise√±ar):** ¬øPor qu√© el autoencoder podr√≠a tener peor rendimiento que 16-QAM en SNR muy alto? Piensa en t√©rminos de optimalidad y capacidad del modelo.

**Pregunta 4.3 (Operar):** Si entrenar√°s el modelo a diferentes SNR (por ejemplo, 5 dB o 15 dB), ¬øc√≥mo cambiar√≠a la curva BER resultante?

**Pregunta 4.4 (CDIO - Integraci√≥n):** En un sistema 5G real, ¬øqu√© ventajas y desventajas tendr√≠a usar un autoencoder aprendido versus una modulaci√≥n est√°ndar como QAM?

## üî¨ Parte 5: Experimentaci√≥n con Diferentes Configuraciones (45 min)

### 5.1 Variaci√≥n del N√∫mero de Mensajes (M)

```python
# Experimentar con diferentes valores de M
print("\nüî¨ Experimentando con diferentes M...\n")

M_values = [4, 8, 16, 32]
ber_results_M = {}

for M in M_values:
    print(f"üì° Entrenando y evaluando para M={M}...")
    
    # Crear nuevo modelo
    model_M = CommunicationNet(
        num_messages=M,
        signal_dims=2,
        intermediate_size=64
    ).to(device)
    
    # Entrenar
    _ = train_communication_system(
        model=model_M,
        num_epochs=80,
        batch_size=256,
        learning_rate=0.001,
        snr_db=10.0,
        device=device,
        verbose=False
    )
    
    # Evaluar
    ber_M = []
    for snr_db in snr_range_db:
        ber = evaluate_ber(model_M, snr_db, 5000, device)
        ber_M.append(ber)
    
    ber_results_M[M] = ber_M
    print(f"  ‚úì M={M} completado\n")

# Graficar comparaci√≥n
plt.figure(figsize=(12, 7))
colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']
markers = ['o', 's', '^', 'D']

for i, M in enumerate(M_values):
    plt.semilogy(snr_range_db, ber_results_M[M], markers[i]+'-', 
                 linewidth=2.5, markersize=8, label=f'M={M} ({int(np.log2(M))} bits)',
                 color=colors[i], markeredgecolor='black')

plt.xlabel('SNR (dB)', fontsize=13)
plt.ylabel('BER', fontsize=13)
plt.title('Efecto del N√∫mero de Mensajes (M) en el Rendimiento', fontsize=14, fontweight='bold')
plt.grid(True, which='both', alpha=0.4)
plt.legend(fontsize=11)
plt.ylim([1e-5, 1])
plt.tight_layout()
plt.show()
```

**Pregunta de Reflexi√≥n 6:** ¬øC√≥mo afecta el incremento de M al rendimiento BER? ¬øPor qu√© sistemas con m√°s mensajes tienen peor BER?

### 5.2 Variaci√≥n de la Dimensi√≥n del Espacio de Se√±al (n)

```python
# Experimentar con diferentes dimensiones n
print("\nüî¨ Experimentando con diferentes n...\n")

n_values = [2, 4, 8]
ber_results_n = {}
constellation_n = {}

for n in n_values:
    print(f"üì° Entrenando y evaluando para n={n}...")
    
    # Crear modelo
    model_n = CommunicationNet(
        num_messages=16,
        signal_dims=n,
        intermediate_size=64
    ).to(device)
    
    # Entrenar
    _ = train_communication_system(
        model=model_n,
        num_epochs=80,
        batch_size=256,
        learning_rate=0.001,
        snr_db=10.0,
        device=device,
        verbose=False
    )
    
    # Guardar constelaci√≥n (solo primeras 2 dimensiones para visualizaci√≥n)
    model_n.eval()
    with torch.no_grad():
        messages = torch.arange(0, 16).to(device)
        symbols = model_n.encoder(messages).cpu().numpy()
        constellation_n[n] = symbols
    
    # Evaluar
    ber_n = []
    for snr_db in snr_range_db:
        ber = evaluate_ber(model_n, snr_db, 5000, device)
        ber_n.append(ber)
    
    ber_results_n[n] = ber_n
    print(f"  ‚úì n={n} completado\n")

# Graficar comparaci√≥n
plt.figure(figsize=(12, 7))
colors_n = ['#e74c3c', '#9b59b6', '#34495e']
markers_n = ['o', 's', '^']

for i, n in enumerate(n_values):
    plt.semilogy(snr_range_db, ber_results_n[n], markers_n[i]+'-', 
                 linewidth=2.5, markersize=8, label=f'n={n} dimensiones',
                 color=colors_n[i], markeredgecolor='black')

plt.xlabel('SNR (dB)', fontsize=13)
plt.ylabel('BER', fontsize=13)
plt.title('Efecto de la Dimensi√≥n del Espacio de Se√±al (n)', fontsize=14, fontweight='bold')
plt.grid(True, which='both', alpha=0.4)
plt.legend(fontsize=11)
plt.ylim([1e-5, 1])
plt.tight_layout()
plt.show()
```

**Actividad 6:** Compara el rendimiento con n=2 vs n=4. ¬øPor qu√© aumentar n mejora el BER? ¬øCu√°l es el costo?

### 5.3 Variaci√≥n del Tama√±o de Capa Intermedia

```python
# Experimentar con diferentes tama√±os de capa oculta
print("\nüî¨ Experimentando con diferentes intermediate_size...\n")

hidden_sizes = [32, 64, 128, 256]
ber_results_hidden = {}

for hidden_size in hidden_sizes:
    print(f"üì° Entrenando y evaluando para hidden_size={hidden_size}...")
    
    model_h = CommunicationNet(
        num_messages=16,
        signal_dims=2,
        intermediate_size=hidden_size
    ).to(device)
    
    # Entrenar
    _ = train_communication_system(
        model=model_h,
        num_epochs=80,
        batch_size=256,
        learning_rate=0.001,
        snr_db=10.0,
        device=device,
        verbose=False
    )
    
    # Evaluar
    ber_h = []
    for snr_db in snr_range_db:
        ber = evaluate_ber(model_h, snr_db, 5000, device)
        ber_h.append(ber)
    
    ber_results_hidden[hidden_size] = ber_h
    print(f"  ‚úì hidden_size={hidden_size} completado\n")

# Graficar
plt.figure(figsize=(12, 7))
colors_h = ['#e67e22', '#16a085', '#8e44ad', '#c0392b']
markers_h = ['o', 's', '^', 'D']

for i, h_size in enumerate(hidden_sizes):
    plt.semilogy(snr_range_db, ber_results_hidden[h_size], markers_h[i]+'-', 
                 linewidth=2.5, markersize=8, label=f'Hidden={h_size}',
                 color=colors_h[i], markeredgecolor='black')

plt.xlabel('SNR (dB)', fontsize=13)
plt.ylabel('BER', fontsize=13)
plt.title('Efecto del Tama√±o de Capa Oculta', fontsize=14, fontweight='bold')
plt.grid(True, which='both', alpha=0.4)
plt.legend(fontsize=11)
plt.ylim([1e-5, 1])
plt.tight_layout()
plt.show()
```

**Pregunta de Reflexi√≥n 7:** ¬øExiste un punto de rendimiento decreciente al aumentar el tama√±o de la capa oculta? ¬øPor qu√©?

### Actividades

**Actividad 5.1:** Entrena y eval√∫a modelos con M = [4, 8, 16, 32]. Grafica todas las curvas BER vs SNR en una sola figura.

**Actividad 5.2:** Entrena modelos con n = [2, 4, 8]. Compara el rendimiento. ¬øCu√°nto mejora n=4 respecto a n=2?

**Actividad 5.3:** Experimenta con diferentes tama√±os de capa oculta [32, 64, 128, 256]. ¬øCu√°l es el tama√±o √≥ptimo?

**Actividad 5.4:** Visualiza las constelaciones aprendidas para diferentes valores de M y n.

### Preguntas de Reflexi√≥n

**Pregunta 5.1 (Concebir):** ¬øC√≥mo afecta el incremento de M al rendimiento BER? ¬øPor qu√© sistemas con m√°s mensajes tienen peor BER? Relaciona esto con la teor√≠a de informaci√≥n de Shannon.

**Pregunta 5.2 (Dise√±ar):** Compara el rendimiento con n=2 vs n=4. ¬øPor qu√© aumentar n mejora el BER? ¬øCu√°l es el costo (eficiencia espectral)?

**Pregunta 5.3 (Implementar):** ¬øExiste un punto de rendimiento decreciente al aumentar el tama√±o de la capa oculta? ¬øPor qu√©? Piensa en t√©rminos de capacidad vs overfitting.

**Pregunta 5.4 (Operar):** Si tuvieras que dise√±ar un sistema para IoT con restricciones de potencia y ancho de banda, ¬øqu√© configuraci√≥n elegir√≠as (M, n, hidden_size)? Justifica tu respuesta.

## üìä Parte 6: An√°lisis Comparativo Final (30 min)

### 6.1 Resumen de Todos los Experimentos

```python
# Crear tabla resumen de todos los experimentos
print("\n" + "="*80)
print(" " * 25 + "RESUMEN DE EXPERIMENTOS")
print("="*80)

# Definir SNR de referencia para comparaci√≥n
snr_ref = 10  # dB
idx_ref = list(snr_range_db).index(snr_ref)

summary_data = {
    'Configuraci√≥n': [],
    'Par√°metros': [],
    f'BER @ {snr_ref}dB': [],
    'Rendimiento Relativo': []
}

# Baseline (modelo original)
baseline_ber = ber_autoencoder[idx_ref]
summary_data['Configuraci√≥n'].append('Baseline')
summary_data['Par√°metros'].append('M=16, n=2, h=64')
summary_data[f'BER @ {snr_ref}dB'].append(f"{baseline_ber:.6f}")
summary_data['Rendimiento Relativo'].append('100%')

# Variaciones de M
for M in M_values:
    ber_val = ber_results_M[M][idx_ref]
    # Rendimiento relativo: valores >100% indican MEJOR rendimiento que baseline (menor BER)
    rel_perf = (baseline_ber / ber_val) * 100 if ber_val > 0 else float('inf')
    summary_data['Configuraci√≥n'].append(f'Variaci√≥n M')
    summary_data['Par√°metros'].append(f'M={M}, n=2, h=64')
    summary_data[f'BER @ {snr_ref}dB'].append(f"{ber_val:.6f}")
    summary_data['Rendimiento Relativo'].append(f'{rel_perf:.1f}%')

# Variaciones de n
for n in n_values:
    ber_val = ber_results_n[n][idx_ref]
    # Rendimiento relativo: valores >100% indican MEJOR rendimiento que baseline (menor BER)
    rel_perf = (baseline_ber / ber_val) * 100 if ber_val > 0 else float('inf')
    summary_data['Configuraci√≥n'].append(f'Variaci√≥n n')
    summary_data['Par√°metros'].append(f'M=16, n={n}, h=64')
    summary_data[f'BER @ {snr_ref}dB'].append(f"{ber_val:.6f}")
    summary_data['Rendimiento Relativo'].append(f'{rel_perf:.1f}%')

# Imprimir tabla
for i in range(len(summary_data['Configuraci√≥n'])):
    if i == 0 or summary_data['Configuraci√≥n'][i] != summary_data['Configuraci√≥n'][i-1]:
        print(f"\n{summary_data['Configuraci√≥n'][i]}:")
        print("-" * 80)
    print(f"  {summary_data['Par√°metros'][i]:<25} BER: {summary_data[f'BER @ {snr_ref}dB'][i]:<12} "
          f"Rendimiento: {summary_data['Rendimiento Relativo'][i]}")

print("\n" + "="*80)
```

### 6.2 Visualizaci√≥n Comparativa de Constelaciones

```python
# Visualizar constelaciones aprendidas para diferentes configuraciones
fig, axes = plt.subplots(2, 2, figsize=(14, 14))
fig.suptitle('Constelaciones Aprendidas - Diferentes Configuraciones', 
             fontsize=16, fontweight='bold')

configs_to_plot = [
    ('M=4, n=2', ber_results_M.get(4) and symbols_np[:4] or symbols_np[:4]),
    ('M=16, n=2', symbols_np),
    ('M=32, n=2', ber_results_M.get(32) and symbols_np[:16] or symbols_np),
    ('M=16, n=4 (proj. 2D)', constellation_n.get(4, symbols_np)[:, :2])
]

for idx, (ax, (title, const)) in enumerate(zip(axes.flat, configs_to_plot)):
    ax.scatter(const[:, 0], const[:, 1], s=120, c=range(len(const)), 
               cmap='tab20', edgecolors='black', linewidth=1.5)
    ax.set_xlabel('I', fontsize=11)
    ax.set_ylabel('Q', fontsize=11)
    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.axis('equal')
    circle = plt.Circle((0, 0), 1, color='r', fill=False, linestyle='--', linewidth=2)
    ax.add_patch(circle)
    
    # Anotar algunos puntos
    for i, (x, y) in enumerate(const):
        if i % max(1, len(const)//16) == 0:  # Anotar cada N puntos
            ax.annotate(f'{i}', (x, y), fontsize=8, ha='center', va='bottom')

plt.tight_layout()
plt.show()
```

### 6.3 Preguntas de Reflexi√≥n Final

1. **Optimizaci√≥n End-to-End:**
   - ¬øCu√°les son las principales ventajas de entrenar todo el sistema conjuntamente?
   - ¬øEn qu√© situaciones las modulaciones cl√°sicas podr√≠an seguir siendo preferibles?

2. **Generalizaci√≥n del Modelo:**
   - El modelo fue entrenado a SNR=10dB. ¬øC√≥mo se desempe√±a a otros SNR?
   - ¬øQu√© estrategias podr√≠as usar para que el modelo generalice a m√∫ltiples SNR?

3. **Complejidad vs Rendimiento:**
   - ¬øCu√°l es el trade-off entre n√∫mero de par√°metros y rendimiento BER?
   - ¬øVale la pena duplicar el tama√±o de la red para mejorar BER en 0.0001?

4. **Aplicaciones Pr√°cticas:**
   - ¬øQu√© desaf√≠os enfrentar√≠as al implementar este sistema en hardware real?
   - ¬øC√≥mo lidiar√≠as con canales que cambian en el tiempo?

5. **Extensiones Avanzadas:**
   - ¬øC√≥mo extender√≠as este enfoque a canales con desvanecimiento (Rayleigh, Rician)?
   - ¬øPodr√≠as adaptar el autoencoder para sistemas MIMO?

### Actividades

**Actividad 6.1:** Completa la tabla resumen comparando todas las configuraciones experimentadas.

**Actividad 6.2:** Visualiza las constelaciones aprendidas lado a lado para diferentes configuraciones.

**Actividad 6.3:** Identifica la configuraci√≥n que ofrece el mejor balance entre rendimiento (BER) y complejidad (par√°metros).

### Preguntas de Reflexi√≥n

**Pregunta 6.1 (Concebir):** ¬øCu√°les son las principales ventajas de entrenar todo el sistema conjuntamente? ¬øEn qu√© situaciones las modulaciones cl√°sicas podr√≠an seguir siendo preferibles?

**Pregunta 6.2 (Dise√±ar):** El modelo fue entrenado a SNR=10dB. ¬øC√≥mo se desempe√±a a otros SNR? ¬øQu√© estrategias podr√≠as usar para que el modelo generalice a m√∫ltiples SNR?

**Pregunta 6.3 (Implementar):** ¬øCu√°l es el trade-off entre n√∫mero de par√°metros y rendimiento BER? ¬øVale la pena duplicar el tama√±o de la red para mejorar BER en 0.0001?

**Pregunta 6.4 (Operar):** ¬øQu√© desaf√≠os enfrentar√≠as al implementar este sistema en hardware real? ¬øC√≥mo lidiar√≠as con canales que cambian en el tiempo?

## üìä An√°lisis Final de Rendimiento

### Resumen de Resultados Clave

**Configuraci√≥n Baseline (M=16, n=2, hidden=64):**
- Loss final de entrenamiento: ~0.0001
- Accuracy de entrenamiento: >99.9%
- BER @ 10 dB (SNR de entrenamiento): ~10^-5
- BER @ 20 dB: Pr√°cticamente 0

**Comparaci√≥n con Modulaciones Cl√°sicas:**
```
SNR (dB)    Autoencoder    16-QAM    16-PSK    Mejora vs QAM
----------------------------------------------------------------
    0           ~0.2         ~0.25      ~0.30         +20%
    5           ~0.05        ~0.08      ~0.12         +38%
   10           ~10^-5       ~10^-4     ~10^-3        10x mejor
   15           ~0           ~0         ~0            Similar
   20           ~0           ~0         ~0            Similar
```

**Hallazgos Principales:**

1. **Ventaja en SNR Medio:** El autoencoder supera significativamente a las modulaciones cl√°sicas en el rango de SNR de entrenamiento (5-15 dB), con mejoras de hasta 10x en BER.

2. **Constelaci√≥n Aprendida:** La red aprende autom√°ticamente una constelaci√≥n que maximiza la distancia entre s√≠mbolos, similar pero no id√©ntica a 16-QAM.

3. **Efecto de M (N√∫mero de Mensajes):**
   - M=4 (2 bits): BER muy bajo incluso en SNR negativo
   - M=16 (4 bits): Balance √≥ptimo rendimiento/eficiencia
   - M=32+ (5+ bits): Degradaci√≥n esperada seg√∫n teor√≠a de Shannon

4. **Efecto de n (Dimensiones):**
   - n=2: Eficiente espectralmente (s√≠mbolos complejos I/Q)
   - n=4: Mejora ~2-3 dB en SNR requerido
   - n=8: Mejora marginal adicional, pobre eficiencia espectral

5. **Efecto de Hidden Size:**
   - 32 neuronas: Suficiente para M‚â§8
   - 64 neuronas: √ìptimo para M=16
   - 128-256: Beneficio marginal, mayor riesgo de overfitting

### An√°lisis CDIO

**Concebir (20%):**
- ‚úÖ Comprensi√≥n del paradigma end-to-end
- ‚úÖ Analog√≠a entre comunicaciones y autoencoders
- ‚úÖ Restricciones de potencia y su importancia
- ‚úÖ Trade-offs fundamentales (M, n, complejidad)

**Dise√±ar (25%):**
- ‚úÖ Arquitectura apropiada para el problema
- ‚úÖ Selecci√≥n de hiperpar√°metros justificada
- ‚úÖ Estrategia de entrenamiento efectiva
- ‚úÖ Experimentos sistem√°ticos y controlados

**Implementar (30%):**
- ‚úÖ C√≥digo funcional y reproducible
- ‚úÖ Entrenamiento convergente
- ‚úÖ Evaluaci√≥n completa BER vs SNR
- ‚úÖ Visualizaciones claras y profesionales

**Operar (25%):**
- ‚úÖ An√°lisis cr√≠tico de resultados
- ‚úÖ Comparaci√≥n con modulaciones est√°ndar
- ‚úÖ Identificaci√≥n de fortalezas y limitaciones
- ‚úÖ Recomendaciones para aplicaciones pr√°cticas

### Limitaciones Identificadas

1. **Generalizaci√≥n a SNR:** El modelo entrenado a un SNR fijo tiene rendimiento sub√≥ptimo en otros SNR.

2. **Canal Espec√≠fico:** El autoencoder est√° optimizado para AWGN. Canales reales (desvanecimiento, no linealidades) requieren reentrenamiento.

3. **Complejidad Computacional:** La inferencia requiere ~10-100x m√°s operaciones que demappers cl√°sicos.

4. **Sincronizaci√≥n:** Asume sincronizaci√≥n perfecta (tiempo, fase, frecuencia). Errores de sincronizaci√≥n no se modelaron.

5. **Escalabilidad:** Para M muy grandes (256+), el entrenamiento se vuelve dif√≠cil y el BER se degrada significativamente.

### Recomendaciones para Aplicaciones Pr√°cticas

**Cu√°ndo usar Autoencoders:**
- ‚úÖ Canales complejos dif√≠ciles de modelar
- ‚úÖ Hardware con imperfecciones conocidas
- ‚úÖ Necesidad de adaptaci√≥n a condiciones espec√≠ficas
- ‚úÖ Recursos computacionales disponibles

**Cu√°ndo usar Modulaciones Cl√°sicas:**
- ‚úÖ Sistemas estandarizados (Wi-Fi, 5G, etc.)
- ‚úÖ Necesidad de interoperabilidad
- ‚úÖ Recursos computacionales muy limitados
- ‚úÖ Requerimientos de baja latencia cr√≠tica

### Extensiones Futuras

1. **Entrenamiento Multi-SNR:** Batch con SNR aleatorio para mejor generalizaci√≥n
2. **Canales Realistas:** Rayleigh, Rician, canales selectivos en frecuencia
3. **Codificaci√≥n de Canal:** Integrar FEC (LDPC, Turbo) en el autoencoder
4. **Sistemas MIMO:** Extender a m√∫ltiples antenas
5. **Adaptaci√≥n Online:** Fine-tuning en tiempo real seg√∫n condiciones del canal

## üéØ EJERCICIOS PROPUESTOS

### Ejercicio 1: Adaptaci√≥n a M√∫ltiples SNR (Dificultad: Media)

**Objetivo:** Mejorar la generalizaci√≥n del autoencoder para que funcione bien en un rango amplio de SNR.

**Tareas:**
1. Modifica el proceso de entrenamiento para usar SNR variable:
   - En cada batch, selecciona SNR aleatorio entre 0-15 dB
   - Implementa una funci√≥n de muestreo uniforme o ponderado de SNR
   - Opcionalmente, usa curriculum learning (empezar con SNR alto, decrementar gradualmente)

2. Entrena el nuevo modelo y comp√°ralo con el baseline:
   - Eval√∫a BER vs SNR en el rango completo [-4, 20] dB
   - Grafica ambas curvas en la misma figura
   - Calcula el BER promedio en el rango [0, 15] dB

3. Analiza la robustez del modelo resultante:
   - ¬øEl modelo multi-SNR tiene mejor o peor rendimiento en SNR espec√≠ficos?
   - ¬øHay un trade-off entre generalizaci√≥n y rendimiento pico?
   - Visualiza la constelaci√≥n aprendida. ¬øEs diferente?

**Entregables:**
- C√≥digo de entrenamiento con SNR aleatorio
- Gr√°ficas comparativas BER vs SNR (baseline vs multi-SNR)
- Tabla con BER promedio en diferentes rangos
- An√°lisis de trade-offs

**Criterios de √âxito:**
- El modelo multi-SNR debe tener BER <2x del baseline en SNR de entrenamiento original
- Mejora demostrable en al menos 50% del rango de SNR
- C√≥digo bien documentado y reproducible
- An√°lisis cr√≠tico fundamentado

---

### Ejercicio 2: Canal Rayleigh con Desvanecimiento (Dificultad: Media-Alta)

**Objetivo:** Extender el autoencoder para trabajar en canales con desvanecimiento realista.

**Tareas:**
1. Implementa un canal Rayleigh:
   - Modelo: $\mathbf{y} = h \cdot \mathbf{x} + \mathbf{n}$, donde $h \sim \text{Rayleigh}(\sigma_h)$
   - Aseg√∫rate de que el canal sea diferenciable para backpropagation
   - Implementa variantes: desvanecimiento r√°pido vs lento

2. Entrena un autoencoder espec√≠fico para este canal:
   - Usa los mismos hiperpar√°metros que el baseline
   - Monitorea convergencia (puede ser m√°s lenta)
   - Guarda checkpoints durante entrenamiento

3. Compara el rendimiento:
   - Eval√∫a BER vs SNR promedio (averaged over fading)
   - Compara con el modelo AWGN puro
   - Eval√∫a el modelo AWGN en canal Rayleigh (sin reentrenar)
   - Visualiza la constelaci√≥n aprendida

4. An√°lisis adicional:
   - ¬øC√≥mo cambia la constelaci√≥n √≥ptima para Rayleigh?
   - ¬øEl modelo es robusto a cambios en la velocidad de desvanecimiento?

**Entregables:**
- Implementaci√≥n del canal Rayleigh
- Modelo entrenado para Rayleigh
- Gr√°ficas comparativas: AWGN-trained vs Rayleigh-trained
- An√°lisis de constelaciones y rendimiento

**Criterios de √âxito:**
- Canal Rayleigh correctamente implementado y validado
- Modelo converge exitosamente en canal Rayleigh
- Mejora >3 dB respecto a usar modelo AWGN en canal Rayleigh
- Documentaci√≥n clara del proceso
- An√°lisis de por qu√© la constelaci√≥n cambia

---

### Ejercicio 3: Autoencoder con Codificaci√≥n de Canal (Dificultad: Alta)

**Objetivo:** Dise√±ar un autoencoder que incluya redundancia (codificaci√≥n de canal) para mejorar la robustez.

**Tareas:**
1. Dise√±a arquitectura con rate < 1:
   - Ejemplo: 4 bits de entrada ‚Üí encoder ‚Üí 8 dimensiones (rate = 0.5)
   - Modifica la arquitectura para soportar n > k (m√°s dimensiones que bits)
   - Mant√©n normalizaci√≥n de potencia

2. Implementa m√∫ltiples configuraciones:
   - Rate 1.0: k=4 bits ‚Üí n=4 dimensiones (baseline, sin redundancia)
   - Rate 0.67: k=4 bits ‚Üí n=6 dimensiones
   - Rate 0.5: k=4 bits ‚Üí n=8 dimensiones
   - Rate 0.33: k=4 bits ‚Üí n=12 dimensiones

3. Compara el rendimiento:
   - Eval√∫a BER vs SNR para todas las configuraciones
   - Calcula la ganancia de codificaci√≥n en dB
   - Analiza el trade-off: eficiencia espectral vs robustez
   - Compara con c√≥digos cl√°sicos (Hamming, Reed-Solomon)

4. Visualizaci√≥n y an√°lisis:
   - Para n=4, 6, 8: visualiza proyecci√≥n 2D de la constelaci√≥n
   - Calcula distancia m√≠nima en espacio n-dimensional
   - Analiza c√≥mo la redundancia mejora la separaci√≥n

**Entregables:**
- C√≥digo de arquitectura con rate variable
- Modelos entrenados para diferentes rates
- Gr√°ficas BER vs SNR comparando todos los rates
- Tabla de trade-offs: rate vs BER @ SNR_ref vs complejidad
- An√°lisis de ganancia de codificaci√≥n

**Criterios de √âxito:**
- Rate 0.5 debe mejorar BER en al menos 2-3 dB respecto a rate 1.0
- Demostraci√≥n clara del trade-off eficiencia vs robustez
- Comparaci√≥n fundamentada con c√≥digos cl√°sicos
- Visualizaciones claras de constelaciones multi-dimensionales
- An√°lisis cuantitativo de ganancia de codificaci√≥n

---

### Ejercicio 4: Visualizaci√≥n Interactiva y An√°lisis de Regiones de Decisi√≥n (Dificultad: Media)

**Objetivo:** Crear visualizaciones que muestren c√≥mo el decoder interpreta diferentes regiones del espacio de se√±al.

**Tareas:**
1. Genera una malla 2D del espacio I/Q:
   - Crea una grid uniforme de puntos en el rango [-1.5, 1.5] √ó [-1.5, 1.5]
   - Resoluci√≥n recomendada: 200√ó200 puntos
   - Para cada punto, eval√∫a la salida del decoder

2. Visualiza las regiones de decisi√≥n:
   - Colorea cada punto seg√∫n el mensaje que el decoder predice
   - Usa diferentes colores para cada uno de los M mensajes
   - Superpone la constelaci√≥n aprendida (s√≠mbolos transmitidos)
   - A√±ade contornos de probabilidad (isol√≠neas)

3. An√°lisis de fronteras de decisi√≥n:
   - ¬øLas fronteras son lineales o no lineales?
   - ¬øHay regiones de alta incertidumbre?
   - Compara con fronteras √≥ptimas (Voronoi)
   - Analiza simetr√≠a y estructura de las regiones

4. Visualizaci√≥n interactiva (opcional):
   - Permite hacer clic en puntos para ver probabilidades
   - Anima c√≥mo las regiones cambian durante el entrenamiento
   - Muestra el efecto del ruido en las decisiones

**Entregables:**
- C√≥digo de visualizaci√≥n de regiones de decisi√≥n
- Gr√°ficas de alta calidad mostrando:
  - Mapa de regiones coloreado
  - Constelaci√≥n superpuesta
  - Contornos de probabilidad
  - Comparaci√≥n con regiones de Voronoi √≥ptimas
- An√°lisis de la forma de las fronteras
- (Opcional) Notebook interactivo o animaciones

**Criterios de √âxito:**
- Visualizaciones claras y profesionales
- Regiones de decisi√≥n correctamente calculadas
- An√°lisis detallado de la forma de las fronteras
- Comparaci√≥n con fronteras te√≥ricas √≥ptimas
- C√≥digo bien documentado y reutilizable

---

### Ejercicio 5: Transfer Learning y Adaptaci√≥n de Dominio (Dificultad: Alta)

**Objetivo:** Usar transfer learning para adaptar r√°pidamente el autoencoder a nuevas condiciones de canal.

**Tareas:**
1. Pre-entrena un modelo robusto:
   - Entrena en canal AWGN con SNR variable [0, 20] dB
   - Usa arquitectura grande (hidden_size=256)
   - Entrena por muchas √©pocas hasta convergencia perfecta

2. Implementa estrategias de transfer learning:
   - **Estrategia 1:** Congelar encoder, fine-tune solo decoder
   - **Estrategia 2:** Congelar primeras capas, fine-tune capas finales
   - **Estrategia 3:** Fine-tune todas las capas con learning rate bajo

3. Adapta a nuevos canales:
   - Canal Rayleigh (desvanecimiento)
   - Canal con offset de fase (error de sincronizaci√≥n)
   - Canal con distorsi√≥n no lineal (ej: saturaci√≥n)

4. Compara con entrenamiento desde cero:
   - N√∫mero de √©pocas necesarias para convergencia
   - BER final alcanzado
   - Estabilidad del entrenamiento
   - Cantidad de datos necesarios

**Entregables:**
- Modelo pre-entrenado robusto
- C√≥digo de transfer learning con las 3 estrategias
- Resultados comparativos: transfer learning vs from scratch
- Curvas de entrenamiento mostrando convergencia m√°s r√°pida
- An√°lisis de qu√© estrategia funciona mejor para cada tipo de canal

**Criterios de √âxito:**
- Transfer learning converge en <50% de las √©pocas necesarias from scratch
- BER final igual o mejor que entrenamiento completo
- Demostraci√≥n en al menos 2 tipos de canal diferentes
- An√°lisis claro de cu√°ndo usar cada estrategia
- C√≥digo modular y reutilizable

## üìù Entregables

Para la evaluaci√≥n completa del laboratorio, debes entregar:

1. **Jupyter Notebook o script Python** (.ipynb o .py) que incluya:
   - Todo el c√≥digo funcional y ejecutable
   - Comentarios explicativos en secciones clave
   - Salidas de ejecuci√≥n (gr√°ficas, m√©tricas)
   - Respuestas a preguntas de reflexi√≥n integradas
   - C√≥digo limpio y bien organizado

2. **Reporte t√©cnico** (4-6 p√°ginas) que incluya:
   - **Introducci√≥n:** Contexto de autoencoders para comunicaciones y objetivos del laboratorio
   - **Marco te√≥rico:** Paradigma end-to-end, restricci√≥n de potencia, funci√≥n de p√©rdida
   - **Metodolog√≠a:** 
     - Descripci√≥n de la arquitectura del autoencoder (encoder y decoder)
     - Proceso de entrenamiento y hiperpar√°metros
     - Configuraci√≥n de experimentos
   - **Resultados:**
     - Curvas de entrenamiento (loss, accuracy)
     - Visualizaciones de constelaciones aprendidas
     - Gr√°ficos comparativos BER vs SNR
     - Resultados de experimentos con diferentes M, n e intermediate_size
     - Tablas de resumen
   - **An√°lisis:**
     - Comparaci√≥n con modulaciones cl√°sicas (16-QAM, 16-PSK)
     - Interpretaci√≥n de constelaciones aprendidas
     - An√°lisis de trade-offs (eficiencia espectral vs robustez)
     - Impacto de par√°metros en el rendimiento
   - **Discusi√≥n:**
     - Ventajas del aprendizaje end-to-end
     - Limitaciones identificadas
     - Aplicaciones pr√°cticas
     - Comparaci√≥n con dise√±o tradicional
   - **Conclusiones:** 
     - Hallazgos principales
     - Recomendaciones para uso en sistemas reales
     - Trabajo futuro

3. **Respuestas a preguntas de reflexi√≥n** de cada parte (pueden estar integradas en el notebook o en el reporte)
   - Clasificadas por dimensi√≥n CDIO (Concebir, Dise√±ar, Implementar, Operar)
   - Respuestas fundamentadas con evidencia experimental

4. **Al menos 2 ejercicios propuestos** completados con:
   - C√≥digo implementado y documentado
   - Resultados experimentales (tablas, gr√°ficas de alta calidad)
   - An√°lisis cr√≠tico de los resultados
   - Conclusiones espec√≠ficas del ejercicio
   - Comparaci√≥n con baseline

5. **Archivos adicionales** (si aplica):
   - Modelos entrenados guardados (.pth)
   - Scripts auxiliares para visualizaci√≥n o utilidades
   - Datos generados (si son relevantes para reproducibilidad)

6. **Presentaci√≥n breve** (5-7 slides) resumiendo los resultados principales (opcional pero recomendado):
   - Motivaci√≥n y objetivos
   - Arquitectura del autoencoder
   - Resultados clave (constelaciones, BER vs SNR)
   - Conclusiones principales

## üéØ Criterios de Evaluaci√≥n (CDIO)

| Criterio | Peso | Descripci√≥n | Indicadores |
|----------|------|-------------|-------------|
| **Concebir** | 20% | Comprensi√≥n del paradigma autoencoder end-to-end, restricci√≥n de potencia, y optimizaci√≥n conjunta | - Claridad en respuestas a preguntas de reflexi√≥n<br>- Correcta interpretaci√≥n de resultados<br>- Comprensi√≥n de trade-offs (M, n, complejidad)<br>- Entendimiento de ventajas vs dise√±o tradicional<br>- Conocimiento de aplicaciones pr√°cticas |
| **Dise√±ar** | 25% | Dise√±o apropiado de arquitecturas, selecci√≥n de hiperpar√°metros, y metodolog√≠a experimental | - Elecci√≥n justificada de arquitectura del encoder/decoder<br>- Configuraci√≥n coherente de par√°metros (M, n, hidden)<br>- Estrategia de entrenamiento apropiada<br>- Dise√±o sistem√°tico de experimentos comparativos<br>- Planificaci√≥n de evaluaci√≥n BER |
| **Implementar** | 30% | Correcta implementaci√≥n del c√≥digo, entrenamiento efectivo, y evaluaci√≥n completa | - C√≥digo funcional sin errores<br>- Implementaci√≥n eficiente y limpia<br>- Uso apropiado de PyTorch<br>- Documentaci√≥n clara del c√≥digo<br>- Reproducibilidad de resultados<br>- Visualizaciones profesionales |
| **Operar** | 25% | An√°lisis de resultados, interpretaci√≥n de m√©tricas, y conclusiones aplicables | - An√°lisis cr√≠tico de constelaciones aprendidas<br>- Interpretaci√≥n correcta de curvas BER<br>- Comparaci√≥n fundamentada con modulaciones cl√°sicas<br>- Identificaci√≥n de limitaciones<br>- Recomendaciones para aplicaciones reales<br>- Calidad del reporte t√©cnico |

### Distribuci√≥n Detallada de Puntos

- **Notebook/c√≥digo completado y funcional:** 30 puntos
  - Implementaci√≥n correcta del autoencoder: 10 pts
  - Entrenamiento convergente y efectivo: 8 pts
  - Evaluaci√≥n completa BER vs SNR: 7 pts
  - Experimentos con diferentes configuraciones: 5 pts

- **Reporte t√©cnico:** 25 puntos
  - Introducci√≥n y marco te√≥rico: 5 pts
  - Metodolog√≠a clara y detallada: 7 pts
  - Resultados y an√°lisis profundo: 8 pts
  - Conclusiones y recomendaciones: 5 pts

- **Respuestas a preguntas de reflexi√≥n:** 20 puntos
  - Profundidad de an√°lisis: 10 pts
  - Conexi√≥n con conceptos CDIO: 5 pts
  - Fundamentaci√≥n con evidencia experimental: 5 pts

- **Ejercicios propuestos completados (m√≠nimo 2):** 15 puntos
  - Implementaci√≥n correcta: 8 pts
  - An√°lisis de resultados: 5 pts
  - Documentaci√≥n y presentaci√≥n: 2 pts

- **Calidad del c√≥digo y presentaci√≥n:** 10 puntos
  - Documentaci√≥n y comentarios: 4 pts
  - Organizaci√≥n y claridad: 3 pts
  - Visualizaciones profesionales: 3 pts

**Total:** 100 puntos

### Desglose por Dimensi√≥n CDIO

**Concebir (20 puntos):**
- Comprensi√≥n de la analog√≠a sistema de comunicaci√≥n ‚Üî autoencoder (5 pts)
- Entendimiento de restricci√≥n de potencia y normalizaci√≥n (4 pts)
- Conocimiento de funci√≥n de p√©rdida y backpropagation a trav√©s del canal (4 pts)
- Comprensi√≥n de ventajas del aprendizaje end-to-end (4 pts)
- An√°lisis de aplicaciones pr√°cticas (3 pts)

**Dise√±ar (25 puntos):**
- Arquitectura del encoder apropiada (6 pts)
- Arquitectura del decoder apropiada (6 pts)
- Selecci√≥n justificada de hiperpar√°metros (M, n, hidden_size) (6 pts)
- Dise√±o de experimentos sistem√°ticos y comparativos (5 pts)
- Estrategia de evaluaci√≥n (SNR range, n√∫mero de muestras) (2 pts)

**Implementar (30 puntos):**
- C√≥digo funcional y ejecutable sin errores (10 pts)
- Entrenamiento exitoso con convergencia (8 pts)
- Evaluaci√≥n correcta de BER en m√∫ltiples configuraciones (6 pts)
- Visualizaciones claras y profesionales (4 pts)
- Documentaci√≥n y reproducibilidad (2 pts)

**Operar (25 puntos):**
- An√°lisis cuantitativo de rendimiento BER (6 pts)
- An√°lisis cualitativo de constelaciones aprendidas (5 pts)
- Comparaci√≥n cr√≠tica con modulaciones est√°ndar (6 pts)
- Respuestas completas y reflexivas a preguntas (5 pts)
- Reporte t√©cnico bien estructurado y profesional (3 pts)

### Criterios de Calidad del C√≥digo

- **Excelente (9-10 puntos):** 
  - C√≥digo limpio, eficiente, bien documentado
  - Sin errores, f√°cilmente reproducible
  - Uso avanzado de PyTorch (GPU, data loaders, etc.)
  - Visualizaciones publication-quality

- **Bueno (7-8 puntos):** 
  - C√≥digo funcional con documentaci√≥n adecuada
  - Pocos errores menores
  - Reproducible con ajustes m√≠nimos
  - Visualizaciones claras

- **Satisfactorio (5-6 puntos):** 
  - C√≥digo funcional con documentaci√≥n b√°sica
  - Algunos errores o warnings
  - Parcialmente reproducible
  - Visualizaciones b√°sicas pero suficientes

- **Insuficiente (<5 puntos):** 
  - C√≥digo no funcional o con errores graves
  - Documentaci√≥n ausente o inadecuada
  - No reproducible
  - Visualizaciones ausentes o confusas

### Criterios de √âxito M√≠nimos

Para aprobar el laboratorio, debes cumplir:

- ‚úÖ **Entrenamiento exitoso:** Loss < 0.01, Accuracy > 95% en el modelo baseline
- ‚úÖ **Rendimiento m√≠nimo:** BER < 10^-3 para SNR ‚â• 12 dB
- ‚úÖ **C√≥digo ejecutable:** Sin errores cr√≠ticos, completamente reproducible
- ‚úÖ **Reporte completo:** Todas las secciones presentes y bien desarrolladas
- ‚úÖ **Respuestas a reflexi√≥n:** Al menos 80% de las preguntas respondidas con profundidad
- ‚úÖ **Ejercicios propuestos:** M√≠nimo 2 ejercicios completados satisfactoriamente
- ‚úÖ **Visualizaciones:** Constelaciones y curvas BER claramente presentadas

### Criterios de Excelencia (>90 puntos)

Para obtener una calificaci√≥n sobresaliente:

- üåü **An√°lisis profundo:** Interpretaci√≥n detallada de por qu√© el autoencoder aprende ciertas constelaciones
- üåü **Comparaciones exhaustivas:** Benchmark contra m√∫ltiples modulaciones y configuraciones
- üåü **Experimentos adicionales:** M√°s de 2 ejercicios propuestos completados
- üåü **C√≥digo avanzado:** Implementaci√≥n de features adicionales (early stopping, learning rate scheduling, etc.)
- üåü **Visualizaciones excepcionales:** Gr√°ficos interactivos, animaciones, o dashboards
- üåü **Conexi√≥n con literatura:** Referencias a papers relevantes y comparaci√≥n con resultados publicados
- üåü **Aplicaciones innovadoras:** Propuesta de aplicaciones o extensiones originales

### R√∫brica de Reporte T√©cnico

| Secci√≥n | Puntos | Criterios de Evaluaci√≥n |
|---------|--------|-------------------------|
| **Introducci√≥n** | 5 | Contexto claro, motivaci√≥n, objetivos espec√≠ficos |
| **Marco Te√≥rico** | 5 | Conceptos fundamentales bien explicados, ecuaciones correctas |
| **Metodolog√≠a** | 7 | Descripci√≥n detallada de arquitectura, hiperpar√°metros, y experimentos |
| **Resultados** | 8 | Presentaci√≥n clara de todos los experimentos con tablas y gr√°ficas |
| **An√°lisis** | 5 | Interpretaci√≥n profunda, conexi√≥n con teor√≠a, trade-offs identificados |
| **Discusi√≥n** | 3 | Ventajas, limitaciones, comparaci√≥n con dise√±o tradicional |
| **Conclusiones** | 2 | S√≠ntesis de hallazgos, recomendaciones, trabajo futuro |
| **Formato** | 0 | Bonus por formato profesional, referencias, ortograf√≠a impecable |

## üìö Referencias Adicionales

### Art√≠culos Fundamentales

1. **O'Shea, T., & Hoydis, J. (2017).** "An Introduction to Deep Learning for the Physical Layer." *IEEE Transactions on Cognitive Communications and Networking*, 3(4), 563-575.
   - Paper seminal que introduce el concepto de autoencoder para comunicaciones

2. **D√∂rner, S., Cammerer, S., Hoydis, J., & ten Brink, S. (2018).** "Deep Learning Based Communication Over the Air." *IEEE Journal on Selected Areas in Communications*, 36(7), 1413-1426.
   - Demostraci√≥n experimental de autoencoders en hardware real

3. **Aoudia, F. A., & Hoydis, J. (2019).** "End-to-End Learning of Communications Systems Without a Channel Model." *52nd Asilomar Conference on Signals, Systems, and Computers*, 298-303.
   - Entrenamiento de autoencoders sin modelo expl√≠cito del canal

4. **Farsad, N., & Goldsmith, A. (2018).** "Neural Network Detection of Data Sequences in Communication Systems." *IEEE Transactions on Signal Processing*, 66(21), 5663-5678.
   - An√°lisis te√≥rico de redes neuronales para detecci√≥n en comunicaciones

5. **Ye, H., Li, G. Y., & Juang, B. H. (2018).** "Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems." *IEEE Wireless Communications Letters*, 7(1), 114-117.
   - Aplicaci√≥n de DL a sistemas OFDM pr√°cticos

### Libros de Texto

6. **Goodfellow, I., Bengio, Y., & Courville, A. (2016).** *Deep Learning*. MIT Press.
   - Cap√≠tulo 14: Autoencoders
   - Disponible gratuitamente: http://www.deeplearningbook.org/

7. **Proakis, J. G., & Salehi, M. (2008).** *Digital Communications* (5th ed.). McGraw-Hill.
   - Cap√≠tulos 4-5: Digital Modulation Techniques
   - Fundamentos te√≥ricos de modulaci√≥n y codificaci√≥n

8. **Goldsmith, A. (2005).** *Wireless Communications*. Cambridge University Press.
   - Cap√≠tulo 5: Performance of Digital Modulation over Wireless Channels
   - L√≠mites te√≥ricos y capacidad de canal

9. **Haykin, S. (2009).** *Communication Systems* (5th ed.). Wiley.
   - Fundamentos de teor√≠a de comunicaciones y procesamiento de se√±ales

### Surveys y Tutoriales

10. **Zhang, C., Patras, P., & Haddadi, H. (2019).** "Deep Learning in Mobile and Wireless Networking: A Survey." *IEEE Communications Surveys & Tutorials*, 21(3), 2224-2287.
    - Revisi√≥n exhaustiva de DL aplicado a comunicaciones wireless

11. **Qin, Z., Ye, H., Li, G. Y., & Juang, B. H. (2019).** "Deep Learning in Physical Layer Communications." *IEEE Wireless Communications*, 26(2), 93-99.
    - Tutorial sobre aplicaciones de DL en capa f√≠sica

12. **Jiang, C., et al. (2017).** "Machine Learning Paradigms for Next-Generation Wireless Networks." *IEEE Wireless Communications*, 24(2), 98-105.
    - Perspectiva sobre ML en redes 5G y beyond

### Documentaci√≥n y Recursos Online

13. **PyTorch Documentation:** https://pytorch.org/docs/stable/index.html
    - Documentaci√≥n oficial de PyTorch

14. **PyTorch Tutorials - Neural Networks:** https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html
    - Tutoriales b√°sicos de redes neuronales

15. **Sionna:** https://nvlabs.github.io/sionna/
    - Framework de NVIDIA para ML aplicado a comunicaciones (incluye autoencoders)

16. **DeepMIMO:** https://www.deepmimo.net/
    - Dataset de canales realistas para entrenar modelos de DL

### C√≥digo y Repositorios

17. **GitHub - CommPy:** https://github.com/veeresht/CommPy
    - Librer√≠a Python para comunicaciones digitales

18. **GitHub - Sionna Examples:** https://github.com/NVlabs/sionna
    - Ejemplos de autoencoders y sistemas end-to-end

19. **Papers with Code - Autoencoders:** https://paperswithcode.com/method/autoencoder
    - C√≥digo de implementaciones state-of-the-art

### Datasets P√∫blicos

20. **DeepSig RadioML Datasets:** https://www.deepsig.ai/datasets
    - Datasets de se√±ales RF para ML

21. **5G Channel Measurement Datasets:** https://www.5g-wave.eu/
    - Mediciones de canales 5G reales

### Art√≠culos Avanzados y Extensiones

22. **Nachmani, E., Be'ery, Y., & Burstein, D. (2016).** "Learning to Decode Linear Codes Using Deep Learning." *54th Allerton Conference*, 341-346.
    - Decodificaci√≥n de c√≥digos FEC con redes neuronales

23. **Cammerer, S., et al. (2020).** "Trainable Communication Systems: Concepts and Prototype." *IEEE Transactions on Communications*, 68(9), 5489-5503.
    - Implementaci√≥n pr√°ctica de sistemas entrenables end-to-end

24. **Aoudia, F. A., Hoydis, J., & G√∂rtz, N. (2021).** "Model-Free Training of End-to-End Communication Systems." *IEEE Journal on Selected Areas in Communications*, 39(1), 199-210.
    - Entrenamiento sin modelo del canal (model-free)

25. **Xu, X., et al. (2021).** "Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning." *ICLR 2021*.
    - Aplicaci√≥n de meta-learning a adaptaci√≥n de autoencoders

### Herramientas de Visualizaci√≥n

26. **TensorBoard:** https://www.tensorflow.org/tensorboard
    - Visualizaci√≥n de m√©tricas de entrenamiento

27. **Weights & Biases:** https://wandb.ai/
    - Plataforma para experimentos de ML

28. **Plotly:** https://plotly.com/python/
    - Visualizaciones interactivas en Python

### Est√°ndares y Especificaciones

29. **3GPP TS 38.211:** Physical channels and modulation (5G NR)
    - Especificaciones de modulaci√≥n en 5G

30. **IEEE 802.11:** Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications
    - Est√°ndares Wi-Fi con m√∫ltiples esquemas de modulaci√≥n

### Blogs y Recursos Educativos

31. **Wireless Pi - Communications DSP:** https://wirelesspi.com/
    - Tutoriales de procesamiento de se√±ales para comunicaciones

32. **Stanford CS229:** http://cs229.stanford.edu/
    - Curso de Machine Learning con fundamentos aplicables

33. **Distill.pub - Machine Learning Research:** https://distill.pub/
    - Art√≠culos interactivos sobre conceptos de ML

### Videos y Cursos Online

34. **DeepLearning.AI - Neural Networks and Deep Learning**
    - Curso de Andrew Ng en Coursera

35. **MIT 6.S191 - Introduction to Deep Learning**
    - Curso MIT con material gratuito

### Conferencias Relevantes

- **ICC (IEEE International Conference on Communications)**
- **GLOBECOM (IEEE Global Communications Conference)**
- **ISIT (IEEE International Symposium on Information Theory)**
- **SPAWC (IEEE Signal Processing Advances in Wireless Communications)**

---

## üéì Notas Finales

**¬°√âxito en tu laboratorio!** üöÄüì°üî¨

**Nota importante:** Este laboratorio introduce el paradigma revolucionario de **optimizaci√≥n end-to-end** en comunicaciones. Los conceptos aprendidos son directamente aplicables a:
- Sistemas 5G/6G con adaptaci√≥n din√°mica
- Comunicaciones √≥pticas con distorsiones no lineales
- IoT con restricciones de potencia
- Sat√©lites con canales variables
- Software Defined Radio (SDR)

### Para Soporte Adicional

- üìñ **Consulta la documentaci√≥n:** `teoria.md` y `README.md` en el directorio del laboratorio
- üíª **Revisa el c√≥digo de referencia:** `autoencoder.py`, `utils.py`
- üìì **Explora notebooks completos:** `laboratorio.ipynb`, `ejercicios-propuestos.ipynb`
- üîç **Lee la documentaci√≥n de PyTorch:** https://pytorch.org/docs/
- üí¨ **Participa en foros:** Stack Overflow, PyTorch Forums, Reddit r/MachineLearning

### Conexi√≥n con Otros Laboratorios

Este laboratorio es fundamental para:
- **Gu√≠a 04:** Codificaci√≥n de canal con autoencoders (extensi√≥n directa)
- **Gu√≠a 08:** Receptores neuronales OFDM (aplicaci√≥n a sistemas multi-portadora)
- **Gu√≠as 15-17 (Sionna):** Sistemas end-to-end avanzados con Sionna framework

### Aplicaciones en el Mundo Real

**Casos de √âxito:**
1. **5G NR:** Adaptaci√≥n de esquemas de modulaci√≥n y codificaci√≥n (MCS)
2. **Starlink:** Optimizaci√≥n de comunicaciones satelitales
3. **Facebook/Meta:** Optimizaci√≥n de backhaul wireless
4. **Qualcomm:** Receptores neurales en chipsets m√≥viles

**Desaf√≠os Abiertos:**
- Entrenamiento online y adaptaci√≥n en tiempo real
- Reducci√≥n de complejidad computacional para dispositivos embebidos
- Robustez a ataques adversarios
- Certificaci√≥n y estandarizaci√≥n de sistemas aprendidos

### Pr√≥ximos Pasos Sugeridos

1. **Experimenta con canales realistas:** Implementa desvanecimiento Rayleigh/Rician
2. **Integra codificaci√≥n de canal:** A√±ade c√≥digos LDPC, Turbo, o Polar
3. **Explora sistemas MIMO:** Extiende a m√∫ltiples antenas
4. **Implementa en hardware:** Usa GNU Radio o USRP para pruebas reales
5. **Lee papers recientes:** Sigue conferencias ICC, GLOBECOM, ISIT

### Contribuci√≥n a la Ciencia

Si obtienes resultados interesantes:
- Documenta tus hallazgos cuidadosamente
- Compara con state-of-the-art
- Considera escribir un paper para conferencias estudiantiles
- Comparte tu c√≥digo en GitHub con licencia open source

---

**"The best way to predict the future is to invent it."** - Alan Kay

¬°Contin√∫a explorando las fronteras entre comunicaciones y machine learning! üåü

