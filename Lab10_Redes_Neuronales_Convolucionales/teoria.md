# Teor√≠a: Redes Neuronales Convolucionales (CNN)

## 1. Introducci√≥n

Las Redes Neuronales Convolucionales (CNN o ConvNets) son una clase especializada de redes neuronales dise√±adas espec√≠ficamente para procesar datos con estructura de cuadr√≠cula, como im√°genes.

### ¬øPor qu√© CNNs para Im√°genes?

**Problema con Redes Densas:**
- Una imagen 224x224 RGB tiene 224 √ó 224 √ó 3 = 150,528 p√≠xeles
- Primera capa densa con 1000 neuronas: 150,528 √ó 1000 = 150 millones de par√°metros
- Extremadamente costoso computacionalmente
- Propensa al overfitting
- Ignora estructura espacial de la imagen

**Soluci√≥n: CNNs**
- Aprovechan estructura espacial local
- Comparten par√°metros (mismo filtro en toda la imagen)
- Invariancia a traslaci√≥n
- Jerarqu√≠a de caracter√≠sticas: bordes ‚Üí formas ‚Üí objetos

## 2. Operaci√≥n de Convoluci√≥n

### 2.1 Convoluci√≥n 1D

La convoluci√≥n es una operaci√≥n matem√°tica entre dos funciones. En se√±ales discretas:

```
(f * g)[n] = Œ£ f[m] ¬∑ g[n - m]
```

**Ejemplo pr√°ctico:**
- Input: [3, 4, 5, 6, 7]
- Kernel: [1, 0, -1]
- Output: aplica el kernel desliz√°ndolo sobre el input

### 2.2 Convoluci√≥n 2D (Im√°genes)

En im√°genes, trabajamos con convoluci√≥n 2D:

```python
# Input: matriz H √ó W
# Kernel: matriz K_h √ó K_w
# Output: (H - K_h + 1) √ó (W - K_w + 1)

Output[i,j] = Œ£ Œ£ Input[i+m, j+n] * Kernel[m, n]
              m n
```

**Visualizaci√≥n:**
```
Input (5√ó5):        Kernel (3√ó3):      Output (3√ó3):
[1 2 3 4 5]         [1  0 -1]          [...]
[1 2 3 4 5]         [1  0 -1]
[1 2 3 4 5]         [1  0 -1]
[1 2 3 4 5]
[1 2 3 4 5]
```

### 2.3 Filtros Cl√°sicos

**Detector de Bordes Verticales:**
```
[-1  0  1]
[-1  0  1]
[-1  0  1]
```

**Detector de Bordes Horizontales:**
```
[-1 -1 -1]
[ 0  0  0]
[ 1  1  1]
```

**Desenfoque (Blur):**
```
[1/9  1/9  1/9]
[1/9  1/9  1/9]
[1/9  1/9  1/9]
```

**Detecci√≥n de Esquinas (Sobel):**
```
[-1  0  1]
[-2  0  2]
[-1  0  1]
```

## 3. Componentes de una CNN

### 3.1 Capa Convolucional

**Par√°metros:**
- **N√∫mero de filtros**: Cu√°ntos feature maps genera
- **Tama√±o del kernel**: T√≠picamente 3√ó3, 5√ó5, 7√ó7
- **Stride**: Paso del desplazamiento (1, 2, ...)
- **Padding**: Relleno de bordes (valid, same)

**C√°lculo de dimensiones:**
```
Output_height = (Input_height - Kernel_height + 2*Padding) / Stride + 1
Output_width = (Input_width - Kernel_width + 2*Padding) / Stride + 1
Output_channels = Number_of_filters
```

**Ejemplo:**
```python
Input: 32√ó32√ó3 (imagen RGB)
Conv2D: 64 filtros, kernel 5√ó5, stride=1, padding=0
Output: 28√ó28√ó64

C√°lculo: (32 - 5 + 0) / 1 + 1 = 28
```

**N√∫mero de par√°metros:**
```
Params = (K_h √ó K_w √ó Input_channels + 1) √ó Num_filters

Ejemplo: (5 √ó 5 √ó 3 + 1) √ó 64 = 4,864 par√°metros
```

### 3.2 Padding

**Valid (sin padding):**
- No agrega bordes
- Output es m√°s peque√±o que input
- Se pierden p√≠xeles de los bordes

**Same (con padding):**
- Agrega bordes de ceros
- Output tiene mismo tama√±o que input (con stride=1)
- Preserva informaci√≥n de bordes

```python
# Para mantener tama√±o con stride=1:
Padding = (Kernel_size - 1) / 2

# Ejemplo con kernel 3√ó3:
Padding = (3 - 1) / 2 = 1
```

### 3.3 Stride

- **Stride = 1**: Mueve filtro 1 p√≠xel a la vez (m√°s overlap)
- **Stride = 2**: Mueve filtro 2 p√≠xeles (menos overlap, reduce tama√±o)
- **Stride > 1**: Alternativa a pooling para reducir dimensionalidad

### 3.4 Capas de Pooling

**Prop√≥sito:**
1. Reducir dimensionalidad espacial
2. Reducir par√°metros y computaci√≥n
3. Proveer invariancia a peque√±as traslaciones
4. Controlar overfitting

**Max Pooling:**
```python
# Toma el valor m√°ximo en cada ventana
Input (4√ó4):         Output (2√ó2) con 2√ó2 pool:
[1  3  2  4]         [6  8]
[5  6  7  8]   ‚Üí     [9  11]
[9  2  1  3]
[4  5  10 11]
```

**Average Pooling:**
```python
# Promedia valores en cada ventana
Input (4√ó4):         Output (2√ó2) con 2√ó2 pool:
[1  3  2  4]         [3.75  5.25]
[5  6  7  8]   ‚Üí     [5.0   6.25]
[9  2  1  3]
[4  5  10 11]
```

**Caracter√≠sticas:**
- Reduce tama√±o espacial pero no n√∫mero de canales
- No tiene par√°metros entrenables
- T√≠picamente 2√ó2 con stride=2

### 3.5 Global Average Pooling (GAP)

- Promedia toda la feature map a un solo valor
- Convierte feature map H√óW√óC en vector de tama√±o C
- Reemplaza capas densas finales
- Menos par√°metros, menos overfitting

```python
Input: 7√ó7√ó512
Global Average Pooling
Output: 1√ó1√ó512 = 512
```

## 4. Arquitectura de una CNN

### 4.1 Estructura T√≠pica

```
Input Image
    ‚Üì
[CONV ‚Üí ReLU ‚Üí POOL] √ó N
    ‚Üì
[CONV ‚Üí ReLU ‚Üí POOL] √ó M
    ‚Üì
Flatten
    ‚Üì
[FC ‚Üí ReLU] √ó K
    ‚Üì
FC ‚Üí Softmax
    ‚Üì
Output (Classes)
```

### 4.2 Jerarqu√≠a de Caracter√≠sticas

**Capas Tempranas (cerca del input):**
- Detectan caracter√≠sticas simples
- Bordes, colores, texturas
- Campo receptivo peque√±o

**Capas Medias:**
- Combinan caracter√≠sticas simples
- Formas, patrones
- Campo receptivo mediano

**Capas Profundas:**
- Caracter√≠sticas de alto nivel
- Partes de objetos, objetos completos
- Campo receptivo grande

### 4.3 Campo Receptivo (Receptive Field)

El campo receptivo de una neurona es la regi√≥n de la entrada que afecta su valor.

**C√°lculo:**
```python
# Capa 1: kernel 3√ó3 ‚Üí receptive field = 3√ó3
# Capa 2: kernel 3√ó3 ‚Üí receptive field = 5√ó5
# Capa 3: kernel 3√ó3 ‚Üí receptive field = 7√ó7

# F√≥rmula general:
RF_l = RF_(l-1) + (kernel_size - 1) * Œ†(stride anterior)
```

## 5. Arquitecturas CNN Famosas

### 5.1 LeNet-5 (1998) - Yann LeCun

**Arquitectura:**
```
INPUT ‚Üí CONV1 ‚Üí POOL1 ‚Üí CONV2 ‚Üí POOL2 ‚Üí FC1 ‚Üí FC2 ‚Üí OUTPUT
32√ó32  ‚Üí  28√ó28 ‚Üí 14√ó14 ‚Üí 10√ó10 ‚Üí  5√ó5  ‚Üí 120 ‚Üí 84  ‚Üí  10
```

**Caracter√≠sticas:**
- Primera CNN exitosa
- Reconocimiento de d√≠gitos (MNIST)
- Usaba Tanh en lugar de ReLU

### 5.2 AlexNet (2012) - Krizhevsky, Sutskever, Hinton

**Arquitectura:**
```
227√ó227√ó3 ‚Üí CONV1(96) ‚Üí POOL ‚Üí CONV2(256) ‚Üí POOL ‚Üí 
CONV3(384) ‚Üí CONV4(384) ‚Üí CONV5(256) ‚Üí POOL ‚Üí FC(4096) ‚Üí FC(4096) ‚Üí FC(1000)
```

**Innovaciones:**
- ReLU activations (6√ó m√°s r√°pido que tanh)
- Dropout para regularizaci√≥n
- Data augmentation
- GPU training
- Gan√≥ ImageNet 2012 (top-5 error: 15.3%)

### 5.3 VGG (2014) - Visual Geometry Group, Oxford

**Caracter√≠sticas:**
- Usa solo conv 3√ó3 y pool 2√ó2
- Arquitectura muy profunda: VGG-16 (16 capas), VGG-19 (19 capas)
- Simple pero muy efectiva
- Muchos par√°metros (~138M en VGG-16)

**VGG-16 Arquitectura:**
```
64 ‚Üí 64 ‚Üí POOL ‚Üí 
128 ‚Üí 128 ‚Üí POOL ‚Üí 
256 ‚Üí 256 ‚Üí 256 ‚Üí POOL ‚Üí 
512 ‚Üí 512 ‚Üí 512 ‚Üí POOL ‚Üí 
512 ‚Üí 512 ‚Üí 512 ‚Üí POOL ‚Üí 
FC(4096) ‚Üí FC(4096) ‚Üí FC(1000)
```

### 5.4 ResNet (2015) - Microsoft Research

**Innovaci√≥n Principal: Skip Connections**
```python
# Bloque residual
x ‚Üí [CONV ‚Üí ReLU ‚Üí CONV] ‚Üí (+) ‚Üí ReLU
 ‚Üì_________________________‚Üë
        (skip connection)
```

**Ventajas:**
- Permite entrenar redes muy profundas (50, 101, 152 capas)
- Soluciona problema de degradaci√≥n
- Gradientes fluyen directamente por skip connections
- Gan√≥ ImageNet 2015 (3.57% top-5 error)

**F√≥rmula:**
```
F(x) = H(x) - x
Output = F(x) + x = H(x)

Donde:
- x: entrada del bloque
- H(x): salida deseada
- F(x): residuo que la red debe aprender
```

### 5.5 Inception / GoogLeNet (2014)

**Innovaci√≥n: M√≥dulo Inception**
- Aplica m√∫ltiples filtros en paralelo (1√ó1, 3√ó3, 5√ó5, pooling)
- Concatena resultados
- Reduce par√°metros con convoluciones 1√ó1

### 5.6 MobileNet (2017)

**Innovaci√≥n: Depthwise Separable Convolutions**
- Separa convoluci√≥n espacial y por canales
- Mucho m√°s eficiente (menos par√°metros y c√≥mputo)
- Ideal para dispositivos m√≥viles

## 6. T√©cnicas Importantes

### 6.1 Batch Normalization

Normaliza activaciones entre batches:
```python
# Para cada feature map:
y = Œ≥ * (x - Œº) / œÉ + Œ≤

Donde:
- Œº, œÉ: media y desviaci√≥n est√°ndar del batch
- Œ≥, Œ≤: par√°metros aprendibles
```

**Beneficios:**
- Acelera entrenamiento
- Permite learning rates m√°s altos
- Reduce dependencia de inicializaci√≥n
- Regularizaci√≥n (ligero efecto de dropout)

### 6.2 Data Augmentation

Aumenta tama√±o del dataset con transformaciones:
- Rotaci√≥n, traslaci√≥n, escala
- Flip horizontal/vertical
- Cambios de brillo, contraste
- Recortes aleatorios (random crops)
- Mezcla (mixup, cutmix)

### 6.3 Transfer Learning

Usa red pre-entrenada en ImageNet:

**Estrategia 1: Feature Extraction**
- Congela capas convolucionales
- Re-entrena solo capas finales
- Usa cuando tienes pocos datos

**Estrategia 2: Fine-Tuning**
- Descongela algunas capas finales
- Re-entrena con learning rate bajo
- Usa cuando tienes datos moderados

### 6.4 Convoluciones 1√ó1

**Prop√≥sitos:**
1. Cambiar n√∫mero de canales (dimensionalidad)
2. Reducir par√°metros antes de conv grandes
3. Agregar no-linealidad extra

```python
Input: 28√ó28√ó192
Conv 1√ó1 con 64 filtros
Output: 28√ó28√ó64

# Reduce de 192 a 64 canales
# Par√°metros: 192 √ó 64 = 12,288
```

## 7. Aplicaciones Avanzadas

### 7.1 Clasificaci√≥n de Im√°genes
- Reconocer categor√≠as de objetos
- Estado del arte: >95% top-5 en ImageNet

### 7.2 Detecci√≥n de Objetos
- Localizar y clasificar m√∫ltiples objetos
- Arquitecturas: YOLO, Faster R-CNN, SSD
- Salida: bounding boxes + clases

### 7.3 Segmentaci√≥n Sem√°ntica
- Clasificar cada p√≠xel
- Arquitecturas: U-Net, SegNet, DeepLab
- Aplicaciones: conducci√≥n aut√≥noma, medicina

### 7.4 Segmentaci√≥n de Instancias
- Detectar y segmentar cada instancia
- Arquitectura: Mask R-CNN
- Segmentaci√≥n a nivel de objeto individual

### 7.5 Face Recognition
- Verificaci√≥n: ¬øSon la misma persona?
- Identificaci√≥n: ¬øQui√©n es esta persona?
- Arquitecturas: FaceNet, DeepFace

### 7.6 Neural Style Transfer
- Aplicar estilo art√≠stico a foto
- Preservar contenido, cambiar estilo
- Usado en apps de filtros art√≠sticos

### 7.7 Diagn√≥stico M√©dico
- Detecci√≥n de tumores en radiograf√≠as
- Clasificaci√≥n de lesiones dermatol√≥gicas
- Segmentaci√≥n de √≥rganos en MRI/CT

## 8. Consideraciones Pr√°cticas

### 8.1 Dise√±o de Arquitectura

**Reglas generales:**
1. Aumenta profundidad gradualmente
2. Duplica filtros cuando reduces tama√±o espacial
3. Usa padding para mantener informaci√≥n de bordes
4. Batch normalization despu√©s de cada conv
5. ReLU como activaci√≥n est√°ndar

**Progresi√≥n com√∫n:**
```
32√ó32√ó3  ‚Üí  32√ó32√ó64  ‚Üí  16√ó16√ó128  ‚Üí  8√ó8√ó256  ‚Üí  4√ó4√ó512
         (conv+BN)    (pool)       (pool)       (pool)
```

### 8.2 Regularizaci√≥n

1. **Dropout**: T√≠picamente 0.5 en capas FC
2. **Weight Decay**: L2 regularization, Œª=1e-4
3. **Data Augmentation**: Cr√≠tico para im√°genes
4. **Batch Normalization**: Regularizaci√≥n impl√≠cita

### 8.3 Optimizaci√≥n

**Learning Rate Schedule:**
- Empezar con LR alto (ej: 0.1)
- Reducir cuando plateau (√ó0.1)
- O usar cosine annealing, step decay

**Optimizadores recomendados:**
- SGD + Momentum (0.9)
- Adam (Œ±=0.001, Œ≤1=0.9, Œ≤2=0.999)

### 8.4 Problemas Comunes

**Overfitting:**
- M√°s data augmentation
- M√°s dropout
- Reducir capacidad del modelo

**Underfitting:**
- Modelo m√°s profundo/ancho
- Entrenar m√°s epochs
- Reducir regularizaci√≥n

**Convergencia lenta:**
- Batch normalization
- Learning rate m√°s alto
- Mejor inicializaci√≥n (Xavier, He)

## 9. Matem√°ticas de Backpropagation en CNN

### 9.1 Gradiente de Convoluci√≥n

Para capa convolucional:
```python
# Forward:
output = input * kernel

# Backward:
‚àÇL/‚àÇinput = ‚àÇL/‚àÇoutput * kernel_rotated_180
‚àÇL/‚àÇkernel = input * ‚àÇL/‚àÇoutput
```

### 9.2 Gradiente de Max Pooling

```python
# Forward: guarda √≠ndices del m√°ximo
max_idx = argmax(window)

# Backward: gradiente va solo a posici√≥n del m√°ximo
‚àÇL/‚àÇinput[max_idx] = ‚àÇL/‚àÇoutput
‚àÇL/‚àÇinput[otros] = 0
```

## 10. Resumen

**CNNs son poderosas porque:**
1. ‚úÖ Aprovechan estructura espacial local
2. ‚úÖ Comparten par√°metros (menos overfitting)
3. ‚úÖ Invariancia a traslaci√≥n
4. ‚úÖ Jerarqu√≠a de caracter√≠sticas
5. ‚úÖ Escalables a im√°genes grandes

**Componentes clave:**
- Convoluci√≥n: detecta patrones locales
- Pooling: reduce dimensionalidad
- Stride/Padding: controla tama√±o de salida
- Arquitectura profunda: jerarqu√≠a de caracter√≠sticas

**Para recordar:**
- Kernels peque√±os (3√ó3) son preferidos
- Batch normalization es casi siempre beneficioso
- Data augmentation es cr√≠tico
- Transfer learning cuando tienes pocos datos
- ResNet y sus skip connections revolucionaron el campo

---

**¬°Las CNNs son el pilar de la visi√≥n computacional moderna!** üñºÔ∏èüëÅÔ∏è
