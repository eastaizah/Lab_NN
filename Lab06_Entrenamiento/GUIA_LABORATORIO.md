# Gu√≠a de Laboratorio: Entrenamiento de Redes Neuronales

## üìã Informaci√≥n del Laboratorio

**T√≠tulo:** Fundamentos de Deep Learning - Entrenamiento de Redes Neuronales  
**C√≥digo:** Lab 06  
**Duraci√≥n:** 2-3 horas  
**Nivel:** Intermedio-Avanzado  

## üéØ Objetivos Espec√≠ficos

Al completar este laboratorio, ser√°s capaz de:

1. Implementar un loop de entrenamiento completo end-to-end
2. Dividir datos correctamente en conjuntos train/validation/test
3. Comprender y aplicar conceptos de √©poca, batch e iteraci√≥n
4. Implementar early stopping para prevenir overfitting
5. Monitorear m√©tricas de entrenamiento y validaci√≥n en tiempo real
6. Detectar y diagnosticar overfitting y underfitting
7. Aplicar t√©cnicas de regularizaci√≥n (L1, L2, Dropout)
8. Implementar learning rate scheduling y decay
9. Optimizar hiperpar√°metros mediante validaci√≥n
10. Guardar y cargar modelos (checkpointing)

## üìö Prerrequisitos

### Conocimientos

- Python intermedio-avanzado (POO, manejo de datos)
- NumPy avanzado (operaciones matriciales, broadcasting)
- Backpropagation y c√°lculo de gradientes (Lab 05)
- Funciones de p√©rdida y activaci√≥n (Labs 03-04)
- Conceptos b√°sicos de overfitting

### Software

- Python 3.8+
- NumPy 1.19+
- Matplotlib (visualizaciones)
- Scikit-learn (divisi√≥n de datos, m√©tricas)
- Jupyter Notebook (recomendado)

### Material de Lectura

Antes de comenzar, lee:
- `teoria.md` - Marco te√≥rico completo sobre entrenamiento
- `README.md` - Estructura del laboratorio y recursos
- Labs anteriores (especialmente Lab 05 sobre Backpropagation)

## üìñ Introducci√≥n

### Del Gradiente a la Inteligencia

Has aprendido a calcular gradientes con backpropagation. Ahora viene la parte emocionante: **entrenar** una red neuronal para que realmente aprenda a resolver problemas.

El entrenamiento es el proceso iterativo mediante el cual:
1. La red hace predicciones
2. Medimos qu√© tan incorrectas son (p√©rdida)
3. Calculamos c√≥mo mejorar (gradientes)
4. Ajustamos los par√°metros (optimizaci√≥n)
5. ¬°Repetimos miles de veces!

**Analog√≠a del aprendizaje:**

Imagina aprender a tocar guitarra:
- **√âpoca**: Practicar la canci√≥n completa una vez
- **Batch**: Practicar un fragmento espec√≠fico
- **Iteraci√≥n**: Un intento de tocar ese fragmento
- **Learning rate**: Qu√© tan dr√°stico ajustas tu t√©cnica
- **Validation**: Tocar para un amigo que te da feedback
- **Early stopping**: Dejar de practicar cuando ya lo tocas bien

### El Loop de Entrenamiento

El coraz√≥n de todo entrenamiento es este loop simple pero poderoso:

```
PARA cada √©poca:
    PARA cada batch de datos:
        1. Forward pass: hacer predicciones
        2. Calcular p√©rdida
        3. Backward pass: calcular gradientes
        4. Actualizar par√°metros
    
    Evaluar en validation set
    
    SI validation no mejora:
        Aplicar early stopping
```

### Conceptos Clave

**√âpoca (Epoch):**
Un pase completo a trav√©s de todos los datos de entrenamiento.
```
1 √©poca = procesar 100% de los datos de entrenamiento
```

**Batch:**
Subconjunto de datos procesados simult√°neamente.
```
Dataset de 1000 muestras, batch size 32
‚Üí 32 batches por √©poca (1000 / 32 ‚âà 31.25)
```

**Iteraci√≥n:**
Un paso de actualizaci√≥n de par√°metros (procesar un batch).
```
Iteraciones por √©poca = total_muestras / batch_size
```

**Learning Rate:**
Controla el tama√±o del paso de optimizaci√≥n.
```
W_nuevo = W_viejo - learning_rate √ó gradiente
```

### Divisi√≥n de Datos

**Train (Entrenamiento)**: 70%
- Datos que el modelo ve durante entrenamiento
- Se usan para ajustar par√°metros (W, b)

**Validation (Validaci√≥n)**: 15%
- Datos para evaluar durante entrenamiento
- Se usan para ajustar hiperpar√°metros
- Detectan overfitting

**Test (Prueba)**: 15%
- Datos que el modelo NUNCA ve durante entrenamiento
- Evaluaci√≥n final del rendimiento real
- Simulan datos del mundo real

**Regla de oro:** ¬°NUNCA uses datos de test para tomar decisiones de entrenamiento!

### Problemas Comunes

**Underfitting (Subajuste):**
```
P√©rdida de entrenamiento: ALTA
P√©rdida de validaci√≥n: ALTA
‚Üí Modelo demasiado simple
```

**Overfitting (Sobreajuste):**
```
P√©rdida de entrenamiento: BAJA
P√©rdida de validaci√≥n: ALTA
‚Üí Modelo memoriz√≥ datos de entrenamiento
```

**Buen ajuste:**
```
P√©rdida de entrenamiento: BAJA
P√©rdida de validaci√≥n: BAJA y cercana a train
‚Üí Modelo generaliza bien
```

### Aplicaciones en el Mundo Real

El entrenamiento efectivo es crucial para:
- **Medicina**: Modelos que diagnostican enfermedades con precisi√≥n
- **Veh√≠culos aut√≥nomos**: Redes que deben generalizar a cualquier carretera
- **Finanzas**: Prevenir overfitting en datos hist√≥ricos
- **PLN**: Modelos de lenguaje entrenados en billones de palabras
- **Visi√≥n**: ImageNet (14M im√°genes, semanas de entrenamiento)

## ü§î Preguntas de Reflexi√≥n Iniciales

1. ¬øPor qu√© necesitamos dividir datos en train/val/test?
2. ¬øQu√© pasar√≠a si usamos todo el dataset para entrenar?
3. ¬øC√≥mo sabemos cu√°ndo detener el entrenamiento?
4. ¬øPor qu√© procesar datos en batches en lugar de todos a la vez?
5. ¬øQu√© indica que un modelo est√° en overfitting?

## üî¨ Parte 1: Fundamentos del Entrenamiento (45 min)

### 1.1 Loop de Entrenamiento B√°sico

Empecemos con la estructura m√°s simple:

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification

# Generar datos sint√©ticos
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,
                          n_informative=15, n_redundant=5, random_state=42)

# Dividir datos
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print(f"Train: {X_train.shape[0]} muestras")
print(f"Validation: {X_val.shape[0]} muestras")
print(f"Test: {X_test.shape[0]} muestras")

# Normalizar datos (importante!)
mean = X_train.mean(axis=0)
std = X_train.std(axis=0)

X_train = (X_train - mean) / (std + 1e-8)
X_val = (X_val - mean) / (std + 1e-8)
X_test = (X_test - mean) / (std + 1e-8)
```

**Simple Training Loop:**

```python
class SimpleTrainer:
    """Trainer b√°sico para redes neuronales"""
    
    def __init__(self, model, learning_rate=0.01):
        self.model = model
        self.lr = learning_rate
        self.history = {
            'train_loss': [],
            'val_loss': []
        }
    
    def train_epoch(self, X, y):
        """Entrena una √©poca completa"""
        # Forward
        predictions = self.model.forward(X)
        
        # Loss
        loss = self.compute_loss(predictions, y)
        
        # Backward
        grad = predictions - y.reshape(-1, 1)
        self.model.backward(grad)
        
        # Update
        self.model.update(self.lr)
        
        return loss
    
    def compute_loss(self, predictions, targets):
        """Binary Cross-Entropy"""
        targets = targets.reshape(-1, 1)
        epsilon = 1e-8
        loss = -np.mean(
            targets * np.log(predictions + epsilon) +
            (1 - targets) * np.log(1 - predictions + epsilon)
        )
        return loss
    
    def evaluate(self, X, y):
        """Eval√∫a el modelo en un dataset"""
        predictions = self.model.forward(X)
        loss = self.compute_loss(predictions, y)
        
        # Accuracy
        pred_classes = (predictions > 0.5).astype(int)
        accuracy = np.mean(pred_classes.flatten() == y)
        
        return loss, accuracy
    
    def train(self, X_train, y_train, X_val, y_val, epochs=100):
        """Loop de entrenamiento completo"""
        print("Iniciando entrenamiento...")
        print("=" * 60)
        
        for epoch in range(epochs):
            # Entrenar
            train_loss = self.train_epoch(X_train, y_train)
            
            # Evaluar
            val_loss, val_acc = self.evaluate(X_val, y_val)
            
            # Guardar historia
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            
            # Mostrar progreso
            if epoch % 10 == 0:
                print(f"Epoch {epoch:3d} | "
                      f"Train Loss: {train_loss:.4f} | "
                      f"Val Loss: {val_loss:.4f} | "
                      f"Val Acc: {val_acc:.4f}")
        
        print("=" * 60)
        print("Entrenamiento completado!")

# Ejemplo de uso (asumiendo que tienes un modelo)
# trainer = SimpleTrainer(model, learning_rate=0.01)
# trainer.train(X_train, y_train, X_val, y_val, epochs=100)
```

### 1.2 Procesamiento en Batches

El procesamiento por batches es esencial para eficiencia:

```python
class BatchTrainer:
    """Trainer con mini-batch SGD"""
    
    def __init__(self, model, learning_rate=0.01, batch_size=32):
        self.model = model
        self.lr = learning_rate
        self.batch_size = batch_size
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': []
        }
    
    def create_batches(self, X, y):
        """Divide datos en batches"""
        n_samples = X.shape[0]
        indices = np.arange(n_samples)
        np.random.shuffle(indices)  # Importante: mezclar datos
        
        batches = []
        for start_idx in range(0, n_samples, self.batch_size):
            end_idx = min(start_idx + self.batch_size, n_samples)
            batch_indices = indices[start_idx:end_idx]
            batches.append((X[batch_indices], y[batch_indices]))
        
        return batches
    
    def train_epoch(self, X_train, y_train):
        """Entrena una √©poca con mini-batches"""
        batches = self.create_batches(X_train, y_train)
        epoch_loss = 0
        
        for batch_X, batch_y in batches:
            # Forward
            predictions = self.model.forward(batch_X)
            
            # Loss
            loss = self.compute_loss(predictions, batch_y)
            epoch_loss += loss
            
            # Backward
            grad = predictions - batch_y.reshape(-1, 1)
            self.model.backward(grad)
            
            # Update
            self.model.update(self.lr)
        
        # P√©rdida promedio de la √©poca
        return epoch_loss / len(batches)
    
    def compute_loss(self, predictions, targets):
        """Binary Cross-Entropy"""
        targets = targets.reshape(-1, 1)
        epsilon = 1e-8
        loss = -np.mean(
            targets * np.log(predictions + epsilon) +
            (1 - targets) * np.log(1 - predictions + epsilon)
        )
        return loss
    
    def evaluate(self, X, y):
        """Eval√∫a modelo"""
        predictions = self.model.forward(X)
        loss = self.compute_loss(predictions, y)
        
        pred_classes = (predictions > 0.5).astype(int)
        accuracy = np.mean(pred_classes.flatten() == y)
        
        return loss, accuracy
    
    def train(self, X_train, y_train, X_val, y_val, epochs=100, verbose=True):
        """Loop de entrenamiento con batches"""
        
        for epoch in range(epochs):
            # Entrenar con batches
            train_loss = self.train_epoch(X_train, y_train)
            train_loss_full, train_acc = self.evaluate(X_train, y_train)
            
            # Validar
            val_loss, val_acc = self.evaluate(X_val, y_val)
            
            # Guardar historia
            self.history['train_loss'].append(train_loss_full)
            self.history['val_loss'].append(val_loss)
            self.history['train_acc'].append(train_acc)
            self.history['val_acc'].append(val_acc)
            
            # Mostrar progreso
            if verbose and epoch % 10 == 0:
                print(f"Epoch {epoch:3d}/{epochs} | "
                      f"Train: Loss={train_loss:.4f} Acc={train_acc:.4f} | "
                      f"Val: Loss={val_loss:.4f} Acc={val_acc:.4f}")
        
        return self.history
```

**Actividad 1.1:** Implementa el trainer y prueba con diferentes batch sizes (1, 16, 32, 128). ¬øQu√© observas?

### 1.3 Visualizaci√≥n del Entrenamiento

```python
import matplotlib.pyplot as plt

def plot_training_history(history):
    """Visualiza curvas de aprendizaje"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # P√©rdida
    ax1.plot(history['train_loss'], label='Train Loss', linewidth=2)
    ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('P√©rdida')
    ax1.set_title('Curva de P√©rdida')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Accuracy
    ax2.plot(history['train_acc'], label='Train Accuracy', linewidth=2)
    ax2.plot(history['val_acc'], label='Val Accuracy', linewidth=2)
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('Accuracy')
    ax2.set_title('Curva de Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Diagn√≥stico
    final_train_loss = history['train_loss'][-1]
    final_val_loss = history['val_loss'][-1]
    gap = final_val_loss - final_train_loss
    
    print("\n=== DIAGN√ìSTICO ===")
    print(f"P√©rdida final - Train: {final_train_loss:.4f}, Val: {final_val_loss:.4f}")
    print(f"Gap (Val - Train): {gap:.4f}")
    
    if gap > 0.1:
        print("‚ö†Ô∏è  OVERFITTING detectado!")
        print("Soluciones: Regularizaci√≥n, Dropout, M√°s datos, Early stopping")
    elif final_train_loss > 0.5:
        print("‚ö†Ô∏è  UNDERFITTING detectado!")
        print("Soluciones: Modelo m√°s complejo, M√°s √©pocas, Ajustar learning rate")
    else:
        print("‚úì Modelo bien ajustado")

# Usar
# plot_training_history(trainer.history)
```

## üî¨ Parte 2: Early Stopping (30 min)

### 2.1 Implementaci√≥n de Early Stopping

Early stopping previene overfitting deteniendo el entrenamiento cuando validation deja de mejorar:

```python
class TrainerWithEarlyStopping:
    """Trainer con early stopping"""
    
    def __init__(self, model, learning_rate=0.01, batch_size=32):
        self.model = model
        self.lr = learning_rate
        self.batch_size = batch_size
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': []
        }
        
        # Para early stopping
        self.best_val_loss = float('inf')
        self.best_weights = None
        self.patience_counter = 0
    
    def create_batches(self, X, y):
        """Divide datos en batches"""
        n_samples = X.shape[0]
        indices = np.arange(n_samples)
        np.random.shuffle(indices)
        
        batches = []
        for start_idx in range(0, n_samples, self.batch_size):
            end_idx = min(start_idx + self.batch_size, n_samples)
            batch_indices = indices[start_idx:end_idx]
            batches.append((X[batch_indices], y[batch_indices]))
        
        return batches
    
    def train_epoch(self, X_train, y_train):
        """Entrena una √©poca"""
        batches = self.create_batches(X_train, y_train)
        epoch_loss = 0
        
        for batch_X, batch_y in batches:
            predictions = self.model.forward(batch_X)
            loss = self.compute_loss(predictions, batch_y)
            epoch_loss += loss
            
            grad = predictions - batch_y.reshape(-1, 1)
            self.model.backward(grad)
            self.model.update(self.lr)
        
        return epoch_loss / len(batches)
    
    def compute_loss(self, predictions, targets):
        """Binary Cross-Entropy"""
        targets = targets.reshape(-1, 1)
        epsilon = 1e-8
        return -np.mean(
            targets * np.log(predictions + epsilon) +
            (1 - targets) * np.log(1 - predictions + epsilon)
        )
    
    def evaluate(self, X, y):
        """Eval√∫a modelo"""
        predictions = self.model.forward(X)
        loss = self.compute_loss(predictions, y)
        pred_classes = (predictions > 0.5).astype(int)
        accuracy = np.mean(pred_classes.flatten() == y)
        return loss, accuracy
    
    def save_checkpoint(self):
        """Guarda mejor modelo"""
        # En una implementaci√≥n real, guardar√≠as W y b de cada capa
        self.best_weights = {
            'layer1_W': self.model.layer1.W.copy(),
            'layer1_b': self.model.layer1.b.copy(),
            'layer2_W': self.model.layer2.W.copy(),
            'layer2_b': self.model.layer2.b.copy(),
        }
    
    def load_checkpoint(self):
        """Restaura mejor modelo"""
        if self.best_weights is not None:
            self.model.layer1.W = self.best_weights['layer1_W'].copy()
            self.model.layer1.b = self.best_weights['layer1_b'].copy()
            self.model.layer2.W = self.best_weights['layer2_W'].copy()
            self.model.layer2.b = self.best_weights['layer2_b'].copy()
    
    def train(self, X_train, y_train, X_val, y_val, 
              epochs=100, patience=10, verbose=True):
        """
        Entrenar con early stopping
        
        patience: n√∫mero de √©pocas sin mejora antes de detener
        """
        print(f"Entrenando con early stopping (patience={patience})...")
        print("=" * 70)
        
        for epoch in range(epochs):
            # Entrenar
            train_loss = self.train_epoch(X_train, y_train)
            train_loss_full, train_acc = self.evaluate(X_train, y_train)
            val_loss, val_acc = self.evaluate(X_val, y_val)
            
            # Guardar historia
            self.history['train_loss'].append(train_loss_full)
            self.history['val_loss'].append(val_loss)
            self.history['train_acc'].append(train_acc)
            self.history['val_acc'].append(val_acc)
            
            # Early stopping logic
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_checkpoint()
                improvement = "‚úì Mejora!"
            else:
                self.patience_counter += 1
                improvement = f"No mejora ({self.patience_counter}/{patience})"
            
            # Mostrar progreso
            if verbose and epoch % 5 == 0:
                print(f"Epoch {epoch:3d}/{epochs} | "
                      f"Train: L={train_loss_full:.4f} A={train_acc:.4f} | "
                      f"Val: L={val_loss:.4f} A={val_acc:.4f} | {improvement}")
            
            # Detener si no hay mejora
            if self.patience_counter >= patience:
                print(f"\n‚ö†Ô∏è  Early stopping en √©poca {epoch}")
                print(f"No mejora en {patience} √©pocas consecutivas")
                print(f"Mejor val_loss: {self.best_val_loss:.4f}")
                
                # Restaurar mejor modelo
                self.load_checkpoint()
                print("Modelo restaurado al mejor checkpoint")
                break
        
        else:
            print("\nEntrenamiento completado sin early stopping")
        
        print("=" * 70)
        return self.history

# Ejemplo de uso
# trainer = TrainerWithEarlyStopping(model, learning_rate=0.01, batch_size=32)
# history = trainer.train(X_train, y_train, X_val, y_val, 
#                         epochs=200, patience=15)
```

**Actividad 2.1:** Experimenta con diferentes valores de patience (5, 10, 20). ¬øC√≥mo afecta al entrenamiento?

## üî¨ Parte 3: Regularizaci√≥n y T√©cnicas Avanzadas (50 min)

### 3.1 Regularizaci√≥n L2 (Weight Decay)

```python
class TrainerWithL2:
    """Trainer con regularizaci√≥n L2"""
    
    def __init__(self, model, learning_rate=0.01, batch_size=32, l2_lambda=0.01):
        self.model = model
        self.lr = learning_rate
        self.batch_size = batch_size
        self.l2_lambda = l2_lambda  # Par√°metro de regularizaci√≥n
        self.history = {'train_loss': [], 'val_loss': []}
    
    def compute_loss_with_l2(self, predictions, targets):
        """P√©rdida con regularizaci√≥n L2"""
        # P√©rdida base (cross-entropy)
        targets = targets.reshape(-1, 1)
        epsilon = 1e-8
        data_loss = -np.mean(
            targets * np.log(predictions + epsilon) +
            (1 - targets) * np.log(1 - predictions + epsilon)
        )
        
        # T√©rmino de regularizaci√≥n L2: Œª * Œ£(W¬≤)
        l2_loss = 0
        l2_loss += np.sum(self.model.layer1.W ** 2)
        l2_loss += np.sum(self.model.layer2.W ** 2)
        l2_loss *= self.l2_lambda / 2
        
        total_loss = data_loss + l2_loss
        
        return total_loss, data_loss, l2_loss
    
    def train_epoch(self, X_train, y_train):
        """Entrena una √©poca con L2"""
        batches = self.create_batches(X_train, y_train)
        epoch_loss = 0
        
        for batch_X, batch_y in batches:
            # Forward
            predictions = self.model.forward(batch_X)
            
            # Loss con L2
            total_loss, data_loss, l2_loss = self.compute_loss_with_l2(
                predictions, batch_y
            )
            epoch_loss += total_loss
            
            # Backward (gradiente de data loss)
            grad = predictions - batch_y.reshape(-1, 1)
            self.model.backward(grad)
            
            # Agregar gradiente L2 a los pesos
            # ‚àÇ(Œª||W||¬≤)/‚àÇW = Œª*W
            self.model.layer1.dW += self.l2_lambda * self.model.layer1.W
            self.model.layer2.dW += self.l2_lambda * self.model.layer2.W
            
            # Update
            self.model.update(self.lr)
        
        return epoch_loss / len(batches)
    
    def create_batches(self, X, y):
        """Crea batches"""
        n_samples = X.shape[0]
        indices = np.arange(n_samples)
        np.random.shuffle(indices)
        
        batches = []
        for start_idx in range(0, n_samples, self.batch_size):
            end_idx = min(start_idx + self.batch_size, n_samples)
            batch_indices = indices[start_idx:end_idx]
            batches.append((X[batch_indices], y[batch_indices]))
        
        return batches

# Comparar con y sin regularizaci√≥n
# trainer_sin_reg = TrainerWithL2(model1, l2_lambda=0.0)
# trainer_con_reg = TrainerWithL2(model2, l2_lambda=0.01)
```

### 3.2 Learning Rate Scheduling

```python
class TrainerWithLRSchedule:
    """Trainer con learning rate scheduling"""
    
    def __init__(self, model, initial_lr=0.1, batch_size=32):
        self.model = model
        self.initial_lr = initial_lr
        self.current_lr = initial_lr
        self.batch_size = batch_size
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'learning_rate': []
        }
    
    def step_decay(self, epoch, drop_factor=0.5, epochs_drop=10):
        """
        Step decay: reduce LR cada X √©pocas
        lr = initial_lr * drop_factor^(epoch // epochs_drop)
        """
        new_lr = self.initial_lr * (drop_factor ** (epoch // epochs_drop))
        return new_lr
    
    def exponential_decay(self, epoch, decay_rate=0.95):
        """
        Exponential decay: reducci√≥n exponencial
        lr = initial_lr * decay_rate^epoch
        """
        new_lr = self.initial_lr * (decay_rate ** epoch)
        return new_lr
    
    def reduce_on_plateau(self, epoch, val_losses, patience=5, factor=0.5):
        """
        Reduce LR si validaci√≥n no mejora
        """
        if len(val_losses) < patience + 1:
            return self.current_lr
        
        # Verificar si hubo mejora en las √∫ltimas 'patience' √©pocas
        recent_best = min(val_losses[-(patience+1):-1])
        current = val_losses[-1]
        
        if current >= recent_best:
            new_lr = self.current_lr * factor
            print(f"   ‚Üí Reducing LR: {self.current_lr:.6f} ‚Üí {new_lr:.6f}")
            return new_lr
        
        return self.current_lr
    
    def train(self, X_train, y_train, X_val, y_val, epochs=100, 
              schedule_type='step', verbose=True):
        """
        Entrenar con LR scheduling
        
        schedule_type: 'step', 'exponential', 'plateau'
        """
        print(f"Entrenando con {schedule_type} LR scheduling...")
        print("=" * 70)
        
        for epoch in range(epochs):
            # Actualizar learning rate
            if schedule_type == 'step':
                self.current_lr = self.step_decay(epoch)
            elif schedule_type == 'exponential':
                self.current_lr = self.exponential_decay(epoch)
            elif schedule_type == 'plateau':
                self.current_lr = self.reduce_on_plateau(
                    epoch, self.history['val_loss']
                )
            
            self.history['learning_rate'].append(self.current_lr)
            
            # Entrenar √©poca
            train_loss = self.train_epoch(X_train, y_train)
            val_loss, val_acc = self.evaluate(X_val, y_val)
            
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            
            if verbose and epoch % 10 == 0:
                print(f"Epoch {epoch:3d} | "
                      f"LR={self.current_lr:.6f} | "
                      f"Train Loss={train_loss:.4f} | "
                      f"Val Loss={val_loss:.4f}")
        
        return self.history
    
    def train_epoch(self, X_train, y_train):
        """Entrena una √©poca"""
        batches = self.create_batches(X_train, y_train)
        epoch_loss = 0
        
        for batch_X, batch_y in batches:
            predictions = self.model.forward(batch_X)
            loss = self.compute_loss(predictions, batch_y)
            epoch_loss += loss
            
            grad = predictions - batch_y.reshape(-1, 1)
            self.model.backward(grad)
            self.model.update(self.current_lr)  # Usar LR actual
        
        return epoch_loss / len(batches)
    
    def compute_loss(self, predictions, targets):
        """Binary Cross-Entropy"""
        targets = targets.reshape(-1, 1)
        epsilon = 1e-8
        return -np.mean(
            targets * np.log(predictions + epsilon) +
            (1 - targets) * np.log(1 - predictions + epsilon)
        )
    
    def evaluate(self, X, y):
        """Eval√∫a modelo"""
        predictions = self.model.forward(X)
        loss = self.compute_loss(predictions, y)
        pred_classes = (predictions > 0.5).astype(int)
        accuracy = np.mean(pred_classes.flatten() == y)
        return loss, accuracy
    
    def create_batches(self, X, y):
        """Crea batches"""
        n_samples = X.shape[0]
        indices = np.arange(n_samples)
        np.random.shuffle(indices)
        
        batches = []
        for start_idx in range(0, n_samples, self.batch_size):
            end_idx = min(start_idx + self.batch_size, n_samples)
            batch_indices = indices[start_idx:end_idx]
            batches.append((X[batch_indices], y[batch_indices]))
        
        return batches

def plot_lr_schedule(history):
    """Visualiza evoluci√≥n del learning rate"""
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history['learning_rate'])
    plt.xlabel('√âpoca')
    plt.ylabel('Learning Rate')
    plt.title('Evoluci√≥n del Learning Rate')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    plt.subplot(1, 2, 2)
    plt.plot(history['train_loss'], label='Train')
    plt.plot(history['val_loss'], label='Validation')
    plt.xlabel('√âpoca')
    plt.ylabel('P√©rdida')
    plt.title('Curvas de Aprendizaje')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
```

**Actividad 3.1:** Compara los tres tipos de scheduling. ¬øCu√°l converge m√°s r√°pido?

## üî¨ Parte 4: Monitoreo y Debugging (35 min)

### 4.1 Dashboard de Monitoreo

```python
class TrainingMonitor:
    """Monitor completo de entrenamiento"""
    
    def __init__(self):
        self.metrics = {
            'epoch': [],
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rate': [],
            'batch_time': [],
            'epoch_time': []
        }
    
    def update(self, epoch, train_loss, val_loss, train_acc, val_acc, lr, epoch_time):
        """Actualiza m√©tricas"""
        self.metrics['epoch'].append(epoch)
        self.metrics['train_loss'].append(train_loss)
        self.metrics['val_loss'].append(val_loss)
        self.metrics['train_acc'].append(train_acc)
        self.metrics['val_acc'].append(val_acc)
        self.metrics['learning_rate'].append(lr)
        self.metrics['epoch_time'].append(epoch_time)
    
    def print_summary(self):
        """Imprime resumen del entrenamiento"""
        print("\n" + "=" * 70)
        print("RESUMEN DEL ENTRENAMIENTO")
        print("=" * 70)
        
        best_val_idx = np.argmin(self.metrics['val_loss'])
        best_epoch = self.metrics['epoch'][best_val_idx]
        
        print(f"\nMejor √©poca: {best_epoch}")
        print(f"  Train Loss: {self.metrics['train_loss'][best_val_idx]:.4f}")
        print(f"  Val Loss: {self.metrics['val_loss'][best_val_idx]:.4f}")
        print(f"  Train Acc: {self.metrics['train_acc'][best_val_idx]:.4f}")
        print(f"  Val Acc: {self.metrics['val_acc'][best_val_idx]:.4f}")
        
        print(f"\n√öltima √©poca: {self.metrics['epoch'][-1]}")
        print(f"  Train Loss: {self.metrics['train_loss'][-1]:.4f}")
        print(f"  Val Loss: {self.metrics['val_loss'][-1]:.4f}")
        print(f"  Train Acc: {self.metrics['train_acc'][-1]:.4f}")
        print(f"  Val Acc: {self.metrics['val_acc'][-1]:.4f}")
        
        total_time = sum(self.metrics['epoch_time'])
        avg_time = np.mean(self.metrics['epoch_time'])
        print(f"\nTiempo total: {total_time:.2f}s")
        print(f"Tiempo promedio por √©poca: {avg_time:.2f}s")
        
        # Diagn√≥stico
        print("\n" + "-" * 70)
        self.diagnose()
        print("=" * 70)
    
    def diagnose(self):
        """Diagnostica problemas comunes"""
        train_loss = self.metrics['train_loss'][-1]
        val_loss = self.metrics['val_loss'][-1]
        gap = val_loss - train_loss
        
        print("DIAGN√ìSTICO:")
        
        if gap > 0.15:
            print("  ‚ö†Ô∏è  OVERFITTING detectado")
            print("      - Val loss >> Train loss")
            print("      - Recomendaciones:")
            print("        * Aumentar regularizaci√≥n (L2, Dropout)")
            print("        * Early stopping con patience menor")
            print("        * M√°s datos de entrenamiento")
            print("        * Reducir complejidad del modelo")
        
        elif train_loss > 0.5:
            print("  ‚ö†Ô∏è  UNDERFITTING detectado")
            print("      - Train loss alto")
            print("      - Recomendaciones:")
            print("        * Aumentar complejidad del modelo")
            print("        * Entrenar m√°s √©pocas")
            print("        * Ajustar learning rate")
            print("        * Verificar preprocesamiento de datos")
        
        elif abs(gap) < 0.05:
            print("  ‚úì BUEN AJUSTE")
            print("      - Train y Val loss similares")
            print("      - Modelo generaliza bien")
        
        # Verificar convergencia
        if len(train_loss) > 10:
            recent_improvement = train_loss[-10] - train_loss[-1]
            if recent_improvement < 0.01:
                print("\n  ‚ÑπÔ∏è  CONVERGENCIA alcanzada")
                print("      - P√©rdida estable en √∫ltimas 10 √©pocas")
    
    def plot_dashboard(self):
        """Visualiza dashboard completo"""
        fig = plt.figure(figsize=(16, 10))
        
        # 1. P√©rdidas
        ax1 = plt.subplot(2, 3, 1)
        ax1.plot(self.metrics['epoch'], self.metrics['train_loss'], 
                label='Train', linewidth=2)
        ax1.plot(self.metrics['epoch'], self.metrics['val_loss'], 
                label='Val', linewidth=2)
        ax1.set_xlabel('√âpoca')
        ax1.set_ylabel('P√©rdida')
        ax1.set_title('Curvas de P√©rdida')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. Accuracy
        ax2 = plt.subplot(2, 3, 2)
        ax2.plot(self.metrics['epoch'], self.metrics['train_acc'], 
                label='Train', linewidth=2)
        ax2.plot(self.metrics['epoch'], self.metrics['val_acc'], 
                label='Val', linewidth=2)
        ax2.set_xlabel('√âpoca')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Curvas de Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. Learning Rate
        ax3 = plt.subplot(2, 3, 3)
        ax3.plot(self.metrics['epoch'], self.metrics['learning_rate'], 
                linewidth=2, color='green')
        ax3.set_xlabel('√âpoca')
        ax3.set_ylabel('Learning Rate')
        ax3.set_title('Learning Rate Schedule')
        ax3.set_yscale('log')
        ax3.grid(True, alpha=0.3)
        
        # 4. Gap (Overfitting indicator)
        ax4 = plt.subplot(2, 3, 4)
        gap = np.array(self.metrics['val_loss']) - np.array(self.metrics['train_loss'])
        ax4.plot(self.metrics['epoch'], gap, linewidth=2, color='red')
        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax4.fill_between(self.metrics['epoch'], 0, gap, 
                        where=(gap>0), alpha=0.3, color='red', label='Overfitting')
        ax4.set_xlabel('√âpoca')
        ax4.set_ylabel('Val Loss - Train Loss')
        ax4.set_title('Gap de Generalizaci√≥n')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # 5. Tiempo por √©poca
        ax5 = plt.subplot(2, 3, 5)
        ax5.plot(self.metrics['epoch'], self.metrics['epoch_time'], 
                linewidth=2, color='purple')
        ax5.set_xlabel('√âpoca')
        ax5.set_ylabel('Tiempo (s)')
        ax5.set_title('Tiempo por √âpoca')
        ax5.grid(True, alpha=0.3)
        
        # 6. Resumen num√©rico
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('off')
        
        best_idx = np.argmin(self.metrics['val_loss'])
        summary_text = f"""
        RESUMEN
        
        Mejor √âpoca: {self.metrics['epoch'][best_idx]}
        Mejor Val Loss: {self.metrics['val_loss'][best_idx]:.4f}
        Mejor Val Acc: {self.metrics['val_acc'][best_idx]:.4f}
        
        Final:
        Train Loss: {self.metrics['train_loss'][-1]:.4f}
        Val Loss: {self.metrics['val_loss'][-1]:.4f}
        Gap: {gap[-1]:.4f}
        
        Total √âpocas: {len(self.metrics['epoch'])}
        Tiempo Total: {sum(self.metrics['epoch_time']):.1f}s
        """
        
        ax6.text(0.1, 0.5, summary_text, fontsize=11, 
                family='monospace', verticalalignment='center')
        
        plt.tight_layout()
        plt.show()
```

**Actividad 4.1:** Usa el monitor para entrenar un modelo y analiza el dashboard completo.

## üìä An√°lisis Final de Rendimiento

### Experimento Completo: Comparaci√≥n de T√©cnicas

```python
import time

def run_experiment(model_fn, X_train, y_train, X_val, y_val, 
                   config_name, **kwargs):
    """Ejecuta un experimento completo de entrenamiento"""
    print(f"\n{'='*70}")
    print(f"Experimento: {config_name}")
    print(f"{'='*70}")
    
    # Crear modelo fresco
    model = model_fn()
    
    # Crear trainer
    trainer = kwargs.get('trainer_class', SimpleTrainer)(model, **kwargs.get('trainer_params', {}))
    
    # Entrenar
    start_time = time.time()
    history = trainer.train(X_train, y_train, X_val, y_val, 
                           epochs=kwargs.get('epochs', 100),
                           verbose=False)
    end_time = time.time()
    
    # Resultados
    final_train_loss = history['train_loss'][-1]
    final_val_loss = history['val_loss'][-1]
    final_train_acc = history['train_acc'][-1]
    final_val_acc = history['val_acc'][-1]
    
    print(f"\nResultados:")
    print(f"  Train Loss: {final_train_loss:.4f} | Accuracy: {final_train_acc:.4f}")
    print(f"  Val Loss: {final_val_loss:.4f} | Accuracy: {final_val_acc:.4f}")
    print(f"  Gap: {final_val_loss - final_train_loss:.4f}")
    print(f"  Tiempo: {end_time - start_time:.2f}s")
    
    return {
        'config': config_name,
        'history': history,
        'train_loss': final_train_loss,
        'val_loss': final_val_loss,
        'train_acc': final_train_acc,
        'val_acc': final_val_acc,
        'time': end_time - start_time
    }

# Ejecutar m√∫ltiples experimentos
results = []

# Experimento 1: Baseline
results.append(run_experiment(
    create_model, X_train, y_train, X_val, y_val,
    "Baseline",
    trainer_class=SimpleTrainer,
    trainer_params={'learning_rate': 0.01},
    epochs=100
))

# Experimento 2: Con mini-batches
results.append(run_experiment(
    create_model, X_train, y_train, X_val, y_val,
    "Mini-batch SGD (batch=32)",
    trainer_class=BatchTrainer,
    trainer_params={'learning_rate': 0.01, 'batch_size': 32},
    epochs=100
))

# Experimento 3: Con early stopping
results.append(run_experiment(
    create_model, X_train, y_train, X_val, y_val,
    "Early Stopping (patience=10)",
    trainer_class=TrainerWithEarlyStopping,
    trainer_params={'learning_rate': 0.01, 'batch_size': 32},
    epochs=200  # M√°s √©pocas pero con early stopping
))

# Comparar resultados
print("\n" + "="*70)
print("COMPARACI√ìN DE EXPERIMENTOS")
print("="*70)

for result in results:
    print(f"\n{result['config']}:")
    print(f"  Val Accuracy: {result['val_acc']:.4f}")
    print(f"  Val Loss: {result['val_loss']:.4f}")
    print(f"  Gap: {result['val_loss'] - result['train_loss']:.4f}")
    print(f"  Tiempo: {result['time']:.2f}s")
```

## üéØ EJERCICIOS PROPUESTOS

### Nivel B√°sico

**Ejercicio 1:** Loop de Entrenamiento B√°sico
```
Implementa un loop de entrenamiento desde cero para:
- Clasificaci√≥n binaria en dataset sint√©tico
- Mostrar progreso cada 10 √©pocas
- Graficar curvas de aprendizaje
```

**Ejercicio 2:** Divisi√≥n de Datos
```
Dado un dataset, implementa:
- Divisi√≥n train/val/test (70/15/15)
- Normalizaci√≥n apropiada
- Verificaci√≥n de distribuci√≥n de clases
```

**Ejercicio 3:** Batch Processing
```
Compara el entrenamiento con diferentes batch sizes:
- Batch completo (batch size = tama√±o del dataset)
- Mini-batch (32, 64, 128)
- Stochastic (batch size = 1)
Analiza tiempo y convergencia.
```

### Nivel Intermedio

**Ejercicio 4:** Early Stopping
```
Implementa early stopping con:
- Patience configurable
- Guardado del mejor modelo
- Restauraci√≥n autom√°tica
- Visualizaci√≥n de cu√°ndo se detuvo
```

**Ejercicio 5:** Learning Rate Finder
```
Implementa el m√©todo "learning rate range test":
- Incrementa LR exponencialmente
- Grafica p√©rdida vs LR
- Encuentra el LR √≥ptimo autom√°ticamente
```

**Ejercicio 6:** Regularizaci√≥n
```
Compara modelos con:
- Sin regularizaci√≥n
- L1 regularizaci√≥n
- L2 regularizaci√≥n
- L1 + L2 (Elastic Net)
Analiza impacto en overfitting.
```

### Nivel Avanzado

**Ejercicio 7:** Sistema Completo de Entrenamiento
```
Implementa un sistema con:
- Mini-batch SGD
- Early stopping
- LR scheduling (reduce on plateau)
- Checkpointing
- Logging completo
- Dashboard de visualizaci√≥n
```

**Ejercicio 8:** Optimizadores Avanzados
```
Implementa desde cero:
- SGD con Momentum
- RMSprop
- Adam
Compara convergencia en diferentes problemas.
```

**Ejercicio 9:** K-Fold Cross-Validation
```
Implementa K-fold CV para:
- Evaluar robustez del modelo
- Estimar error de generalizaci√≥n
- Seleccionar hiperpar√°metros
Promedia resultados de K modelos.
```

## üìù Entregables

### 1. C√≥digo Fuente
- `trainer.py`: Clase principal de entrenamiento
- `early_stopping.py`: Implementaci√≥n de early stopping
- `lr_scheduler.py`: Schedulers de learning rate
- `regularization.py`: T√©cnicas de regularizaci√≥n
- `monitor.py`: Sistema de monitoreo
- `experiments.ipynb`: Notebook con experimentos

### 2. Experimentos
- Comparaci√≥n de batch sizes
- An√°lisis de early stopping
- Evaluaci√≥n de regularizaci√≥n
- Comparaci√≥n de LR schedules
- Resultados en datasets reales

### 3. Visualizaciones
- Curvas de aprendizaje
- Dashboards de entrenamiento
- Comparaciones de configuraciones
- An√°lisis de convergencia

### 4. Reporte (3-4 p√°ginas)
- Metodolog√≠a de experimentaci√≥n
- Resultados y an√°lisis
- Conclusiones sobre mejores pr√°cticas
- Recomendaciones para diferentes escenarios

## üéØ Criterios de Evaluaci√≥n (CDIO)

### Conceive (Concebir) - 25%
- [ ] Comprensi√≥n del proceso de entrenamiento completo
- [ ] Identificaci√≥n de hiperpar√°metros clave
- [ ] Dise√±o de experimentos apropiados
- [ ] Planificaci√≥n de estrategias de validaci√≥n

### Design (Dise√±ar) - 25%
- [ ] Implementaci√≥n correcta del loop de entrenamiento
- [ ] C√≥digo modular y extensible
- [ ] Sistema de monitoreo efectivo
- [ ] Manejo apropiado de datos

### Implement (Implementar) - 30%
- [ ] Early stopping funciona correctamente
- [ ] Regularizaci√≥n reduce overfitting
- [ ] LR scheduling mejora convergencia
- [ ] Resultados reproducibles

### Operate (Operar) - 20%
- [ ] Experimentos bien dise√±ados
- [ ] An√°lisis cr√≠tico de resultados
- [ ] Comparaciones significativas
- [ ] Documentaci√≥n clara

## üìã R√∫brica de Evaluaci√≥n

| Criterio | Excelente (90-100%) | Bueno (75-89%) | Satisfactorio (60-74%) | Insuficiente (<60%) |
|----------|-------------------|--------------|---------------------|------------------|
| **Loop Entrenamiento** | Completo, robusto, eficiente | Funcional y correcto | B√°sico pero funciona | Errores o incompleto |
| **Early Stopping** | Implementado perfectamente | Funciona bien | Implementaci√≥n b√°sica | No funciona |
| **Regularizaci√≥n** | M√∫ltiples t√©cnicas, bien aplicadas | Al menos una t√©cnica | Intentado pero limitado | No implementado |
| **Experimentos** | Extensivos, bien dise√±ados | Buenos experimentos | Experimentos b√°sicos | Experimentos insuficientes |
| **An√°lisis** | Profundo, insights valiosos | Buen an√°lisis | An√°lisis superficial | An√°lisis pobre |

## üìö Referencias Adicionales

### Papers Fundamentales
1. Bottou, L. (2010). "Large-Scale Machine Learning with Stochastic Gradient Descent"
2. Hinton, G. et al. (2012). "Improving neural networks by preventing co-adaptation of feature detectors" (Dropout)
3. Ioffe, S. & Szegedy, C. (2015). "Batch Normalization"
4. Smith, L. N. (2017). "Cyclical Learning Rates for Training Neural Networks"

### Recursos Online
- **Deep Learning Book** (Goodfellow): Cap√≠tulo 8 - Optimization
- **CS231n Stanford**: Notas sobre entrenamiento de redes neuronales
- **Fast.ai**: Practical Deep Learning for Coders
- **Distill.pub**: Visualizaciones interactivas sobre optimizaci√≥n

### Herramientas
- Scikit-learn: train_test_split, cross_validation
- TensorBoard: Visualizaci√≥n de entrenamiento
- Weights & Biases: Tracking de experimentos

## üéì Notas Finales

### Mejores Pr√°cticas

1. **Siempre normaliza tus datos**: Hace que el entrenamiento sea m√°s estable y r√°pido.

2. **Usa early stopping**: Previene overfitting y ahorra tiempo de c√≥mputo.

3. **Monitorea train y validation**: La relaci√≥n entre ambas te dice mucho sobre tu modelo.

4. **Empieza simple**: Baseline simple primero, luego a√±ade complejidad.

5. **Guarda checkpoints**: Nunca sabes cu√°ndo necesitar√°s volver a un modelo anterior.

### Errores Comunes

‚ùå **No mezclar datos antes de crear batches**: Lleva a mal entrenamiento
‚ùå **Usar datos de test para early stopping**: ¬°Test debe ser intocable!
‚ùå **No normalizar datos**: Entrenamiento inestable
‚ùå **Learning rate muy alto**: Divergencia
‚ùå **No monitorear validation**: No detectas overfitting

### Checklist de Entrenamiento

Antes de entrenar:
- [ ] Datos normalizados
- [ ] Divisi√≥n train/val/test correcta
- [ ] Batch size razonable (16-128)
- [ ] Learning rate inicial apropiado (0.001-0.01)
- [ ] Early stopping configurado
- [ ] Monitoreo activado

Durante entrenamiento:
- [ ] Verificar que p√©rdida baja
- [ ] Monitorear gap train-val
- [ ] Observar convergencia
- [ ] Verificar tiempo por √©poca

Despu√©s de entrenar:
- [ ] Evaluar en test set
- [ ] Analizar errores
- [ ] Guardar modelo
- [ ] Documentar configuraci√≥n

### Reflexi√≥n Final

**El entrenamiento es donde la teor√≠a se encuentra con la pr√°ctica**. Puedes tener el mejor algoritmo del mundo, pero sin un buen proceso de entrenamiento, no funcionar√°.

Las t√©cnicas que aprendiste aqu√≠:
- Son usadas en TODOS los modelos de producci√≥n
- Son la diferencia entre 80% y 95% de accuracy
- Te permiten diagnosticar y solucionar problemas
- Son transferibles a cualquier framework (PyTorch, TensorFlow)

### Pr√≥ximos Pasos

En el siguiente laboratorio (Lab 07), aprender√°s:
- M√©tricas de evaluaci√≥n detalladas
- Matriz de confusi√≥n
- Precision, Recall, F1-Score
- ROC curves y AUC
- An√°lisis de errores sistem√°tico

¬°El entrenamiento es donde todo cobra vida! üöÄ

---

**"In theory, there is no difference between theory and practice. In practice, there is."** - Yogi Berra

**¬°El entrenamiento es donde todo cobra vida! üöÄ**
