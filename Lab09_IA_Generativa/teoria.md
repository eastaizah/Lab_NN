# Teor√≠a: IA Generativa

## Introducci√≥n

La **Inteligencia Artificial Generativa** es una rama del deep learning que se enfoca en **crear** contenido nuevo en lugar de simplemente clasificarlo o predecirlo. Modelos generativos pueden crear im√°genes, texto, m√∫sica, videos y m√°s.

## ¬øQu√© es un Modelo Generativo?

### Modelos Discriminativos vs Generativos

**Modelos Discriminativos** (lo que hemos visto):
- Aprenden P(y|X): probabilidad de la etiqueta dado los datos
- Ejemplos: Clasificaci√≥n de im√°genes, detecci√≥n de objetos
- Pregunta: "¬øEs esto un gato o un perro?"

**Modelos Generativos**:
- Aprenden P(X): la distribuci√≥n de los datos
- O P(X|y): datos condicionados a etiquetas
- Pueden generar nuevas muestras
- Pregunta: "¬øPuedes crear una imagen de un gato?"

## Tipos de Modelos Generativos

### 1. Autoencoders (AE)

**Concepto**: Codificar datos a espacio latente comprimido y reconstruir.

**Arquitectura**:
```
Input ‚Üí [Encoder] ‚Üí Latent Space ‚Üí [Decoder] ‚Üí Output
  X   ‚Üí    œÜ(X)    ‚Üí      z      ‚Üí    œà(z)   ‚Üí   X'
```

**Objetivo**: Minimizar error de reconstrucci√≥n
```
Loss = ||X - X'||¬≤
```

**Aplicaciones**:
- Reducci√≥n de dimensionalidad
- Denoising (eliminaci√≥n de ruido)
- Compresi√≥n

**Limitaci√≥n**: No genera datos nuevos muy bien

### 2. Variational Autoencoders (VAE)

**Concepto**: Autoencoders con espacio latente probabil√≠stico.

**Diferencia clave**: En lugar de codificar a un punto z, codifica a una **distribuci√≥n** p(z).

**Arquitectura**:
```
X ‚Üí [Encoder] ‚Üí Œº, œÉ ‚Üí Sample z ~ N(Œº, œÉ¬≤) ‚Üí [Decoder] ‚Üí X'
```

**Loss function**:
```
Loss = Reconstruction Loss + KL Divergence
     = ||X - X'||¬≤ + KL(q(z|X) || p(z))
```

Donde:
- Reconstruction: qu√© tan bien reconstruye
- KL Divergence: qu√© tan cerca est√° q(z|X) de prior p(z)

**Ventajas**:
- Espacio latente continuo y suave
- Puede generar nuevas muestras
- Control sobre generaci√≥n

**Aplicaciones**:
- Generaci√≥n de caras
- Generaci√≥n de d√≠gitos
- Interpolaci√≥n entre im√°genes

### 3. Generative Adversarial Networks (GANs)

**Concepto**: Dos redes compiten entre s√≠.

**Componentes**:

1. **Generator (Generador)**: Crea datos falsos
   ```
   z (ruido) ‚Üí G(z) ‚Üí imagen falsa
   ```

2. **Discriminator (Discriminador)**: Distingue real de falso
   ```
   X ‚Üí D(X) ‚Üí probabilidad de ser real
   ```

**Entrenamiento adversarial**:
```
while not converged:
    # Entrenar Discriminador
    - Clasificar im√°genes reales como reales
    - Clasificar im√°genes falsas (de G) como falsas
    
    # Entrenar Generador
    - Generar im√°genes que enga√±en a D
```

**Funci√≥n objetivo**:
```
min_G max_D E[log D(X)] + E[log(1 - D(G(z)))]
```

**Ventajas**:
- Genera im√°genes de alta calidad
- No requiere emparejamiento expl√≠cito

**Desaf√≠os**:
- Entrenamiento inestable
- Mode collapse (genera poca variedad)
- Dif√≠cil de debuggear

**Aplicaciones**:
- Generaci√≥n de caras realistas
- Style transfer
- Imagen a imagen (pix2pix)
- Super-resoluci√≥n

### 4. Diffusion Models

**Concepto**: Aprender a revertir un proceso de difusi√≥n (a√±adir ruido).

**Proceso**:

1. **Forward (difusi√≥n)**: A√±adir ruido gradualmente
   ```
   X‚ÇÄ ‚Üí X‚ÇÅ ‚Üí X‚ÇÇ ‚Üí ... ‚Üí X‚Çú (puro ruido)
   ```

2. **Reverse (denoising)**: Aprender a remover ruido
   ```
   X‚Çú ‚Üí X‚Çú‚Çã‚ÇÅ ‚Üí ... ‚Üí X‚ÇÅ ‚Üí X‚ÇÄ (imagen limpia)
   ```

**Ventajas**:
- Entrenamiento m√°s estable que GANs
- Calidad de imagen excelente
- Control flexible

**Ejemplos**:
- DALL-E 2
- Stable Diffusion
- Midjourney

### 5. Transformers Generativos

**Concepto**: Usar arquitectura transformer para generaci√≥n.

**Ejemplos famosos**:
- **GPT (Generative Pre-trained Transformer)**: Texto
- **DALL-E**: Im√°genes desde texto
- **Codex**: C√≥digo

**Caracter√≠sticas**:
- Autoregresivo: genera token por token
- Escalable a modelos enormes
- Few-shot learning

## Comparaci√≥n de Modelos

| Modelo | Calidad | Diversidad | Estabilidad | Control | Velocidad |
|--------|---------|-----------|-------------|---------|-----------|
| **Autoencoder** | Baja | Baja | Alta | Bajo | R√°pida |
| **VAE** | Media | Media | Alta | Medio | R√°pida |
| **GAN** | Alta | Media | Baja | Medio | R√°pida |
| **Diffusion** | Muy Alta | Alta | Alta | Alto | Lenta |
| **Transformer** | Muy Alta | Alta | Media | Alto | Media |

## Aplicaciones de IA Generativa

### 1. Generaci√≥n de Im√°genes
- Crear arte
- Dise√±o de productos
- Edici√≥n fotogr√°fica
- S√≠ntesis de caras

### 2. Generaci√≥n de Texto
- Chatbots (ChatGPT)
- Escritura creativa
- Res√∫menes
- Traducci√≥n

### 3. Generaci√≥n de Audio
- S√≠ntesis de voz
- Generaci√≥n de m√∫sica
- Efectos de sonido

### 4. Generaci√≥n de Video
- Deepfakes
- Animaci√≥n
- Efectos especiales

### 5. Dise√±o Molecular
- Descubrimiento de f√°rmacos
- Dise√±o de prote√≠nas

## Implementaci√≥n B√°sica: VAE Simple

### Arquitectura

```python
class VAE:
    def __init__(self):
        # Encoder
        self.encoder = [
            Dense(128) ‚Üí ReLU,
            Dense(64) ‚Üí ReLU,
            Dense(latent_dim * 2)  # Œº y log(œÉ¬≤)
        ]
        
        # Decoder
        self.decoder = [
            Dense(64) ‚Üí ReLU,
            Dense(128) ‚Üí ReLU,
            Dense(input_dim) ‚Üí Sigmoid
        ]
```

### Forward Pass

```python
def encode(X):
    h = encoder(X)
    Œº = h[:, :latent_dim]
    log_œÉ¬≤ = h[:, latent_dim:]
    return Œº, log_œÉ¬≤

def reparameterize(Œº, log_œÉ¬≤):
    œÉ = exp(0.5 * log_œÉ¬≤)
    Œµ = random_normal()
    z = Œº + œÉ * Œµ
    return z

def decode(z):
    return decoder(z)

def forward(X):
    Œº, log_œÉ¬≤ = encode(X)
    z = reparameterize(Œº, log_œÉ¬≤)
    X_reconstructed = decode(z)
    return X_reconstructed, Œº, log_œÉ¬≤
```

### Loss Function

```python
def vae_loss(X, X_recon, Œº, log_œÉ¬≤):
    # Reconstruction loss
    recon_loss = binary_crossentropy(X, X_recon)
    
    # KL divergence
    kl_loss = -0.5 * sum(1 + log_œÉ¬≤ - Œº¬≤ - exp(log_œÉ¬≤))
    
    return recon_loss + kl_loss
```

## Implementaci√≥n B√°sica: GAN Simple

### Arquitectura

```python
class Generator:
    def __init__(self):
        self.model = [
            Dense(128) ‚Üí ReLU,
            Dense(256) ‚Üí ReLU,
            Dense(784) ‚Üí Tanh  # Salida en [-1, 1]
        ]
    
    def forward(noise):
        return model(noise)

class Discriminator:
    def __init__(self):
        self.model = [
            Dense(256) ‚Üí LeakyReLU,
            Dense(128) ‚Üí LeakyReLU,
            Dense(1) ‚Üí Sigmoid  # Probabilidad de ser real
        ]
    
    def forward(X):
        return model(X)
```

### Entrenamiento

```python
for epoch in range(epochs):
    # 1. Entrenar Discriminador
    real_data = sample_real_data()
    fake_data = generator(random_noise())
    
    d_loss_real = -log(discriminator(real_data))
    d_loss_fake = -log(1 - discriminator(fake_data))
    d_loss = d_loss_real + d_loss_fake
    
    update(discriminator, d_loss)
    
    # 2. Entrenar Generador
    fake_data = generator(random_noise())
    g_loss = -log(discriminator(fake_data))
    
    update(generator, g_loss)
```

## Conceptos Avanzados

### Latent Space (Espacio Latente)

**Definici√≥n**: Representaci√≥n comprimida y continua de datos.

**Propiedades deseables**:
- **Continuidad**: Puntos cercanos ‚Üí salidas similares
- **Completitud**: Cualquier punto ‚Üí salida v√°lida
- **Disentanglement**: Cada dimensi√≥n controla un factor

**Aplicaciones**:
- Interpolaci√≥n
- Manipulaci√≥n sem√°ntica
- Exploraci√≥n de variedades

### Conditional Generation

**Concepto**: Generar condicionado a informaci√≥n adicional.

```
z, y (etiqueta) ‚Üí Generator ‚Üí imagen de clase y
```

**Ejemplos**:
- "Genera un d√≠gito 7"
- "Genera una cara rubia"
- Text-to-image: "Un gato tocando piano"

### Mode Collapse (en GANs)

**Problema**: El generador produce poca variedad.

**S√≠ntoma**: Todas las muestras se parecen

**Soluciones**:
- Minibatch discrimination
- Unrolled GANs
- Gradient penalties (WGAN)

## Evaluaci√≥n de Modelos Generativos

### M√©tricas

1. **Inception Score (IS)**
   - Eval√∫a calidad y diversidad
   - Basado en clasificador pre-entrenado

2. **Fr√©chet Inception Distance (FID)**
   - Compara distribuciones de caracter√≠sticas
   - M√°s bajo = mejor

3. **Evaluaci√≥n Humana**
   - A/B testing
   - Encuestas de calidad

### Desaf√≠os

- No hay m√©trica perfecta
- Trade-off calidad vs diversidad
- Depende de la aplicaci√≥n

## √âtica y Consideraciones

### Riesgos

1. **Deepfakes**: Desinformaci√≥n
2. **Sesgos**: Reproducir sesgos de datos
3. **Derechos de autor**: ¬øDe qui√©n es el arte generado?
4. **Uso malicioso**: Falsificaci√≥n, fraude

### Mitigaciones

- Watermarking
- Detecci√≥n de contenido generado
- Transparencia
- Regulaci√≥n
- Educaci√≥n p√∫blica

## Futuro de IA Generativa

### Tendencias

1. **Multimodalidad**: Texto + imagen + audio
2. **Personalizaci√≥n**: Modelos personalizados
3. **Eficiencia**: Modelos m√°s peque√±os y r√°pidos
4. **Control**: Mejor control sobre generaci√≥n
5. **Democratizaci√≥n**: Acceso m√°s amplio

### √Åreas Emergentes

- Generaci√≥n 3D
- Video de alta calidad
- Dise√±o molecular
- C√≥digo (GitHub Copilot)

## Recursos de Aprendizaje

### Papers Fundamentales

- **VAE**: "Auto-Encoding Variational Bayes" (Kingma & Welling, 2013)
- **GAN**: "Generative Adversarial Networks" (Goodfellow et al., 2014)
- **Diffusion**: "Denoising Diffusion Probabilistic Models" (Ho et al., 2020)

### Tutoriales

- PyTorch GAN Tutorial
- TensorFlow VAE Guide
- Hugging Face Diffusers

## Resumen

**IA Generativa** es fascinante porque:
- Crea en lugar de clasificar
- Tiene aplicaciones creativas
- Est√° en r√°pida evoluci√≥n

**Modelos principales**:
- **VAE**: Espacio latente probabil√≠stico
- **GAN**: Competici√≥n adversarial
- **Diffusion**: Proceso de denoising
- **Transformers**: Generaci√≥n autoregresiva

**Clave**: Balance entre calidad, diversidad y control

---

**¬°El futuro es generativo! üé®ü§ñ**
